{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q1Q9mWDrgMUn"
   },
   "source": [
    "# 9장. 문서 요약 (Text Summarization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hpTxmnbx8v6m"
   },
   "source": [
    "## Mecab 설치 (필요시)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "qsWnZkd78qCA",
    "outputId": "2db7bd4a-91a5-46f4-8219-bfb7b45f7859"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "python3-dev is already the newest version (3.6.7-1~18.04).\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnvidia-common-440\n",
      "Use 'sudo apt autoremove' to remove it.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
      "Collecting konlpy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
      "\u001b[K     |████████████████████████████████| 19.4MB 69.2MB/s \n",
      "\u001b[?25hCollecting tweepy>=3.7.0\n",
      "  Downloading https://files.pythonhosted.org/packages/bb/7c/99d51f80f3b77b107ebae2634108717362c059a41384a1810d13e2429a81/tweepy-3.9.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)\n",
      "Collecting beautifulsoup4==4.6.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 8.0MB/s \n",
      "\u001b[?25hCollecting colorama\n",
      "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
      "Collecting JPype1>=0.7.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/49/725710351d78d26c65337b1e3b322d7b27b34b704535ab56afc0d9ab0ffd/JPype1-1.0.1-cp36-cp36m-manylinux2010_x86_64.whl (3.8MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8MB 51.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.12.0)\n",
      "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
      "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
      "Installing collected packages: tweepy, beautifulsoup4, colorama, JPype1, konlpy\n",
      "  Found existing installation: tweepy 3.6.0\n",
      "    Uninstalling tweepy-3.6.0:\n",
      "      Successfully uninstalled tweepy-3.6.0\n",
      "  Found existing installation: beautifulsoup4 4.6.3\n",
      "    Uninstalling beautifulsoup4-4.6.3:\n",
      "      Successfully uninstalled beautifulsoup4-4.6.3\n",
      "Successfully installed JPype1-1.0.1 beautifulsoup4-4.6.0 colorama-0.4.3 konlpy-0.5.2 tweepy-3.9.0\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "curl is already the newest version (7.58.0-2ubuntu3.9).\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnvidia-common-440\n",
      "Use 'sudo apt autoremove' to remove it.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
      "Installing automake (A dependency for mecab-ko)\n",
      "Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
      "Get:2 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
      "Hit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
      "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
      "Get:5 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,626 B]\n",
      "Get:6 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
      "Ign:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
      "Get:9 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [9,279 B]\n",
      "Ign:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
      "Hit:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
      "Get:12 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [1,005 kB]\n",
      "Hit:13 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
      "Get:14 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [89.9 kB]\n",
      "Get:15 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [869 kB]\n",
      "Get:16 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [43.3 kB]\n",
      "Get:17 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,849 kB]\n",
      "Get:18 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [892 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [104 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,406 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [13.6 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [1,307 kB]\n",
      "Get:23 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [8,432 B]\n",
      "Fetched 7,889 kB in 1s (5,558 kB/s)\n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnvidia-common-440\n",
      "Use 'sudo apt autoremove' to remove it.\n",
      "The following additional packages will be installed:\n",
      "  autoconf autotools-dev libsigsegv2 m4\n",
      "Suggested packages:\n",
      "  autoconf-archive gnu-standards autoconf-doc libtool gettext m4-doc\n",
      "The following NEW packages will be installed:\n",
      "  autoconf automake autotools-dev libsigsegv2 m4\n",
      "0 upgraded, 5 newly installed, 0 to remove and 66 not upgraded.\n",
      "Need to get 1,082 kB of archives.\n",
      "After this operation, 3,994 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsigsegv2 amd64 2.12-1 [14.7 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 m4 amd64 1.4.18-1 [197 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 autoconf all 2.69-11 [322 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 autotools-dev all 20180224.1 [39.6 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 automake all 1:1.15.1-3ubuntu2 [509 kB]\n",
      "Fetched 1,082 kB in 0s (9,053 kB/s)\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 5.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "dpkg-preconfigure: unable to re-open stdin: \n",
      "Selecting previously unselected package libsigsegv2:amd64.\n",
      "(Reading database ... 144465 files and directories currently installed.)\n",
      "Preparing to unpack .../libsigsegv2_2.12-1_amd64.deb ...\n",
      "Unpacking libsigsegv2:amd64 (2.12-1) ...\n",
      "Selecting previously unselected package m4.\n",
      "Preparing to unpack .../archives/m4_1.4.18-1_amd64.deb ...\n",
      "Unpacking m4 (1.4.18-1) ...\n",
      "Selecting previously unselected package autoconf.\n",
      "Preparing to unpack .../autoconf_2.69-11_all.deb ...\n",
      "Unpacking autoconf (2.69-11) ...\n",
      "Selecting previously unselected package autotools-dev.\n",
      "Preparing to unpack .../autotools-dev_20180224.1_all.deb ...\n",
      "Unpacking autotools-dev (20180224.1) ...\n",
      "Selecting previously unselected package automake.\n",
      "Preparing to unpack .../automake_1%3a1.15.1-3ubuntu2_all.deb ...\n",
      "Unpacking automake (1:1.15.1-3ubuntu2) ...\n",
      "Setting up libsigsegv2:amd64 (2.12-1) ...\n",
      "Setting up m4 (1.4.18-1) ...\n",
      "Setting up autotools-dev (20180224.1) ...\n",
      "Setting up autoconf (2.69-11) ...\n",
      "Setting up automake (1:1.15.1-3ubuntu2) ...\n",
      "update-alternatives: using /usr/bin/automake-1.15 to provide /usr/bin/automake (automake) in auto mode\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
      "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
      "\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
      "Install mecab-ko-dic\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 1381k  100 1381k    0     0   916k      0  0:00:01  0:00:01 --:--:-- 2731k\n",
      "mecab-0.996-ko-0.9.2/\n",
      "mecab-0.996-ko-0.9.2/example/\n",
      "mecab-0.996-ko-0.9.2/example/example.cpp\n",
      "mecab-0.996-ko-0.9.2/example/example_lattice.cpp\n",
      "mecab-0.996-ko-0.9.2/example/example_lattice.c\n",
      "mecab-0.996-ko-0.9.2/example/example.c\n",
      "mecab-0.996-ko-0.9.2/example/thread_test.cpp\n",
      "mecab-0.996-ko-0.9.2/mecab-config.in\n",
      "mecab-0.996-ko-0.9.2/man/\n",
      "mecab-0.996-ko-0.9.2/man/Makefile.am\n",
      "mecab-0.996-ko-0.9.2/man/mecab.1\n",
      "mecab-0.996-ko-0.9.2/man/Makefile.in\n",
      "mecab-0.996-ko-0.9.2/mecab.iss.in\n",
      "mecab-0.996-ko-0.9.2/config.guess\n",
      "mecab-0.996-ko-0.9.2/README\n",
      "mecab-0.996-ko-0.9.2/COPYING\n",
      "mecab-0.996-ko-0.9.2/CHANGES.md\n",
      "mecab-0.996-ko-0.9.2/README.md\n",
      "mecab-0.996-ko-0.9.2/INSTALL\n",
      "mecab-0.996-ko-0.9.2/config.sub\n",
      "mecab-0.996-ko-0.9.2/configure.in\n",
      "mecab-0.996-ko-0.9.2/swig/\n",
      "mecab-0.996-ko-0.9.2/swig/Makefile\n",
      "mecab-0.996-ko-0.9.2/swig/version.h.in\n",
      "mecab-0.996-ko-0.9.2/swig/version.h\n",
      "mecab-0.996-ko-0.9.2/swig/MeCab.i\n",
      "mecab-0.996-ko-0.9.2/aclocal.m4\n",
      "mecab-0.996-ko-0.9.2/LGPL\n",
      "mecab-0.996-ko-0.9.2/Makefile.am\n",
      "mecab-0.996-ko-0.9.2/configure\n",
      "mecab-0.996-ko-0.9.2/tests/\n",
      "mecab-0.996-ko-0.9.2/tests/autolink/\n",
      "mecab-0.996-ko-0.9.2/tests/autolink/unk.def\n",
      "mecab-0.996-ko-0.9.2/tests/autolink/dicrc\n",
      "mecab-0.996-ko-0.9.2/tests/autolink/dic.csv\n",
      "mecab-0.996-ko-0.9.2/tests/autolink/test\n",
      "mecab-0.996-ko-0.9.2/tests/autolink/char.def\n",
      "mecab-0.996-ko-0.9.2/tests/autolink/matrix.def\n",
      "mecab-0.996-ko-0.9.2/tests/autolink/test.gld\n",
      "mecab-0.996-ko-0.9.2/tests/t9/\n",
      "mecab-0.996-ko-0.9.2/tests/t9/unk.def\n",
      "mecab-0.996-ko-0.9.2/tests/t9/ipadic.pl\n",
      "mecab-0.996-ko-0.9.2/tests/t9/dicrc\n",
      "mecab-0.996-ko-0.9.2/tests/t9/dic.csv\n",
      "mecab-0.996-ko-0.9.2/tests/t9/test\n",
      "mecab-0.996-ko-0.9.2/tests/t9/char.def\n",
      "mecab-0.996-ko-0.9.2/tests/t9/matrix.def\n",
      "mecab-0.996-ko-0.9.2/tests/t9/mkdic.pl\n",
      "mecab-0.996-ko-0.9.2/tests/t9/test.gld\n",
      "mecab-0.996-ko-0.9.2/tests/cost-train/\n",
      "mecab-0.996-ko-0.9.2/tests/cost-train/ipa.train\n",
      "mecab-0.996-ko-0.9.2/tests/cost-train/ipa.test\n",
      "mecab-0.996-ko-0.9.2/tests/cost-train/seed/\n",
      "mecab-0.996-ko-0.9.2/tests/cost-train/seed/rewrite.def\n",
      "mecab-0.996-ko-0.9.2/tests/cost-train/seed/feature.def\n",
      "mecab-0.996-ko-0.9.2/tests/cost-train/seed/unk.def\n",
      "mecab-0.996-ko-0.9.2/tests/cost-train/seed/dicrc\n",
      "mecab-0.996-ko-0.9.2/tests/cost-train/seed/dic.csv\n",
      "mecab-0.996-ko-0.9.2/tests/cost-train/seed/char.def\n",
      "mecab-0.996-ko-0.9.2/tests/cost-train/seed/matrix.def\n",
      "mecab-0.996-ko-0.9.2/tests/run-eval.sh\n",
      "mecab-0.996-ko-0.9.2/tests/run-cost-train.sh\n",
      "mecab-0.996-ko-0.9.2/tests/Makefile.am\n",
      "mecab-0.996-ko-0.9.2/tests/katakana/\n",
      "mecab-0.996-ko-0.9.2/tests/katakana/unk.def\n",
      "mecab-0.996-ko-0.9.2/tests/katakana/dicrc\n",
      "mecab-0.996-ko-0.9.2/tests/katakana/dic.csv\n",
      "mecab-0.996-ko-0.9.2/tests/katakana/test\n",
      "mecab-0.996-ko-0.9.2/tests/katakana/char.def\n",
      "mecab-0.996-ko-0.9.2/tests/katakana/matrix.def\n",
      "mecab-0.996-ko-0.9.2/tests/katakana/test.gld\n",
      "mecab-0.996-ko-0.9.2/tests/eval/\n",
      "mecab-0.996-ko-0.9.2/tests/eval/answer\n",
      "mecab-0.996-ko-0.9.2/tests/eval/system\n",
      "mecab-0.996-ko-0.9.2/tests/eval/test.gld\n",
      "mecab-0.996-ko-0.9.2/tests/shiin/\n",
      "mecab-0.996-ko-0.9.2/tests/shiin/unk.def\n",
      "mecab-0.996-ko-0.9.2/tests/shiin/dicrc\n",
      "mecab-0.996-ko-0.9.2/tests/shiin/dic.csv\n",
      "mecab-0.996-ko-0.9.2/tests/shiin/test\n",
      "mecab-0.996-ko-0.9.2/tests/shiin/char.def\n",
      "mecab-0.996-ko-0.9.2/tests/shiin/matrix.def\n",
      "mecab-0.996-ko-0.9.2/tests/shiin/mkdic.pl\n",
      "mecab-0.996-ko-0.9.2/tests/shiin/test.gld\n",
      "mecab-0.996-ko-0.9.2/tests/latin/\n",
      "mecab-0.996-ko-0.9.2/tests/latin/unk.def\n",
      "mecab-0.996-ko-0.9.2/tests/latin/dicrc\n",
      "mecab-0.996-ko-0.9.2/tests/latin/dic.csv\n",
      "mecab-0.996-ko-0.9.2/tests/latin/test\n",
      "mecab-0.996-ko-0.9.2/tests/latin/char.def\n",
      "mecab-0.996-ko-0.9.2/tests/latin/matrix.def\n",
      "mecab-0.996-ko-0.9.2/tests/latin/test.gld\n",
      "mecab-0.996-ko-0.9.2/tests/chartype/\n",
      "mecab-0.996-ko-0.9.2/tests/chartype/unk.def\n",
      "mecab-0.996-ko-0.9.2/tests/chartype/dicrc\n",
      "mecab-0.996-ko-0.9.2/tests/chartype/dic.csv\n",
      "mecab-0.996-ko-0.9.2/tests/chartype/test\n",
      "mecab-0.996-ko-0.9.2/tests/chartype/char.def\n",
      "mecab-0.996-ko-0.9.2/tests/chartype/matrix.def\n",
      "mecab-0.996-ko-0.9.2/tests/chartype/test.gld\n",
      "mecab-0.996-ko-0.9.2/tests/run-dics.sh\n",
      "mecab-0.996-ko-0.9.2/tests/ngram/\n",
      "mecab-0.996-ko-0.9.2/tests/ngram/unk.def\n",
      "mecab-0.996-ko-0.9.2/tests/ngram/dicrc\n",
      "mecab-0.996-ko-0.9.2/tests/ngram/dic.csv\n",
      "mecab-0.996-ko-0.9.2/tests/ngram/test\n",
      "mecab-0.996-ko-0.9.2/tests/ngram/char.def\n",
      "mecab-0.996-ko-0.9.2/tests/ngram/matrix.def\n",
      "mecab-0.996-ko-0.9.2/tests/ngram/test.gld\n",
      "mecab-0.996-ko-0.9.2/tests/Makefile.in\n",
      "mecab-0.996-ko-0.9.2/ltmain.sh\n",
      "mecab-0.996-ko-0.9.2/config.rpath\n",
      "mecab-0.996-ko-0.9.2/config.h.in\n",
      "mecab-0.996-ko-0.9.2/mecabrc.in\n",
      "mecab-0.996-ko-0.9.2/GPL\n",
      "mecab-0.996-ko-0.9.2/Makefile.train\n",
      "mecab-0.996-ko-0.9.2/ChangeLog\n",
      "mecab-0.996-ko-0.9.2/install-sh\n",
      "mecab-0.996-ko-0.9.2/AUTHORS\n",
      "mecab-0.996-ko-0.9.2/doc/\n",
      "mecab-0.996-ko-0.9.2/doc/bindings.html\n",
      "mecab-0.996-ko-0.9.2/doc/posid.html\n",
      "mecab-0.996-ko-0.9.2/doc/unk.html\n",
      "mecab-0.996-ko-0.9.2/doc/learn.html\n",
      "mecab-0.996-ko-0.9.2/doc/format.html\n",
      "mecab-0.996-ko-0.9.2/doc/libmecab.html\n",
      "mecab-0.996-ko-0.9.2/doc/mecab.css\n",
      "mecab-0.996-ko-0.9.2/doc/feature.html\n",
      "mecab-0.996-ko-0.9.2/doc/Makefile.am\n",
      "mecab-0.996-ko-0.9.2/doc/soft.html\n",
      "mecab-0.996-ko-0.9.2/doc/en/\n",
      "mecab-0.996-ko-0.9.2/doc/en/bindings.html\n",
      "mecab-0.996-ko-0.9.2/doc/dic-detail.html\n",
      "mecab-0.996-ko-0.9.2/doc/flow.png\n",
      "mecab-0.996-ko-0.9.2/doc/mecab.html\n",
      "mecab-0.996-ko-0.9.2/doc/index.html\n",
      "mecab-0.996-ko-0.9.2/doc/result.png\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/tab_a.png\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/globals_eval.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Tagger-members.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/functions_vars.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/doxygen.css\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/tab_r.gif\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Lattice.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/functions.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Tagger.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/mecab_8h_source.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/tabs.css\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/nav_f.png\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/tab_b.png\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/globals.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/nav_h.png\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/tab_h.png\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Model.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/globals_func.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/closed.png\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/tab_l.gif\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__path__t-members.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/functions_func.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/globals_type.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Lattice-members.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__node__t.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/namespacemembers_func.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/tab_s.png\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__dictionary__info__t-members.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/namespacemembers_type.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Model-members.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__dictionary__info__t.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/namespaces.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/namespacemembers.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/namespaceMeCab.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__path__t.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/files.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__node__t-members.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/index.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/annotated.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/globals_defs.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/classes.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/mecab_8h-source.html\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/doxygen.png\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/tab_b.gif\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/bc_s.png\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/open.png\n",
      "mecab-0.996-ko-0.9.2/doc/doxygen/mecab_8h.html\n",
      "mecab-0.996-ko-0.9.2/doc/dic.html\n",
      "mecab-0.996-ko-0.9.2/doc/partial.html\n",
      "mecab-0.996-ko-0.9.2/doc/feature.png\n",
      "mecab-0.996-ko-0.9.2/doc/Makefile.in\n",
      "mecab-0.996-ko-0.9.2/missing\n",
      "mecab-0.996-ko-0.9.2/BSD\n",
      "mecab-0.996-ko-0.9.2/NEWS\n",
      "mecab-0.996-ko-0.9.2/mkinstalldirs\n",
      "mecab-0.996-ko-0.9.2/src/\n",
      "mecab-0.996-ko-0.9.2/src/dictionary.h\n",
      "mecab-0.996-ko-0.9.2/src/writer.h\n",
      "mecab-0.996-ko-0.9.2/src/utils.h\n",
      "mecab-0.996-ko-0.9.2/src/string_buffer.cpp\n",
      "mecab-0.996-ko-0.9.2/src/tokenizer.cpp\n",
      "mecab-0.996-ko-0.9.2/src/make.bat\n",
      "mecab-0.996-ko-0.9.2/src/mecab.h\n",
      "mecab-0.996-ko-0.9.2/src/freelist.h\n",
      "mecab-0.996-ko-0.9.2/src/string_buffer.h\n",
      "mecab-0.996-ko-0.9.2/src/learner_tagger.h\n",
      "mecab-0.996-ko-0.9.2/src/dictionary_compiler.cpp\n",
      "mecab-0.996-ko-0.9.2/src/eval.cpp\n",
      "mecab-0.996-ko-0.9.2/src/mecab-system-eval.cpp\n",
      "mecab-0.996-ko-0.9.2/src/darts.h\n",
      "mecab-0.996-ko-0.9.2/src/param.h\n",
      "mecab-0.996-ko-0.9.2/src/char_property.h\n",
      "mecab-0.996-ko-0.9.2/src/learner_node.h\n",
      "mecab-0.996-ko-0.9.2/src/mecab-dict-gen.cpp\n",
      "mecab-0.996-ko-0.9.2/src/mecab-dict-index.cpp\n",
      "mecab-0.996-ko-0.9.2/src/winmain.h\n",
      "mecab-0.996-ko-0.9.2/src/thread.h\n",
      "mecab-0.996-ko-0.9.2/src/context_id.cpp\n",
      "mecab-0.996-ko-0.9.2/src/Makefile.am\n",
      "mecab-0.996-ko-0.9.2/src/connector.h\n",
      "mecab-0.996-ko-0.9.2/src/common.h\n",
      "mecab-0.996-ko-0.9.2/src/dictionary_rewriter.cpp\n",
      "mecab-0.996-ko-0.9.2/src/Makefile.msvc.in\n",
      "mecab-0.996-ko-0.9.2/src/dictionary_rewriter.h\n",
      "mecab-0.996-ko-0.9.2/src/feature_index.h\n",
      "mecab-0.996-ko-0.9.2/src/iconv_utils.cpp\n",
      "mecab-0.996-ko-0.9.2/src/char_property.cpp\n",
      "mecab-0.996-ko-0.9.2/src/mecab-test-gen.cpp\n",
      "mecab-0.996-ko-0.9.2/src/tagger.cpp\n",
      "mecab-0.996-ko-0.9.2/src/mecab-cost-train.cpp\n",
      "mecab-0.996-ko-0.9.2/src/learner.cpp\n",
      "mecab-0.996-ko-0.9.2/src/dictionary.cpp\n",
      "mecab-0.996-ko-0.9.2/src/lbfgs.cpp\n",
      "mecab-0.996-ko-0.9.2/src/ucs.h\n",
      "mecab-0.996-ko-0.9.2/src/writer.cpp\n",
      "mecab-0.996-ko-0.9.2/src/learner_tagger.cpp\n",
      "mecab-0.996-ko-0.9.2/src/lbfgs.h\n",
      "mecab-0.996-ko-0.9.2/src/libmecab.cpp\n",
      "mecab-0.996-ko-0.9.2/src/tokenizer.h\n",
      "mecab-0.996-ko-0.9.2/src/mecab.cpp\n",
      "mecab-0.996-ko-0.9.2/src/utils.cpp\n",
      "mecab-0.996-ko-0.9.2/src/dictionary_generator.cpp\n",
      "mecab-0.996-ko-0.9.2/src/param.cpp\n",
      "mecab-0.996-ko-0.9.2/src/context_id.h\n",
      "mecab-0.996-ko-0.9.2/src/mmap.h\n",
      "mecab-0.996-ko-0.9.2/src/viterbi.h\n",
      "mecab-0.996-ko-0.9.2/src/viterbi.cpp\n",
      "mecab-0.996-ko-0.9.2/src/stream_wrapper.h\n",
      "mecab-0.996-ko-0.9.2/src/feature_index.cpp\n",
      "mecab-0.996-ko-0.9.2/src/nbest_generator.h\n",
      "mecab-0.996-ko-0.9.2/src/ucstable.h\n",
      "mecab-0.996-ko-0.9.2/src/nbest_generator.cpp\n",
      "mecab-0.996-ko-0.9.2/src/iconv_utils.h\n",
      "mecab-0.996-ko-0.9.2/src/connector.cpp\n",
      "mecab-0.996-ko-0.9.2/src/Makefile.in\n",
      "mecab-0.996-ko-0.9.2/src/scoped_ptr.h\n",
      "mecab-0.996-ko-0.9.2/Makefile.in\n",
      "checking for a BSD-compatible install... /usr/bin/install -c\n",
      "checking whether build environment is sane... yes\n",
      "checking for a thread-safe mkdir -p... /bin/mkdir -p\n",
      "checking for gawk... no\n",
      "checking for mawk... mawk\n",
      "checking whether make sets $(MAKE)... yes\n",
      "checking for gcc... gcc\n",
      "checking whether the C compiler works... yes\n",
      "checking for C compiler default output file name... a.out\n",
      "checking for suffix of executables... \n",
      "checking whether we are cross compiling... no\n",
      "checking for suffix of object files... o\n",
      "checking whether we are using the GNU C compiler... yes\n",
      "checking whether gcc accepts -g... yes\n",
      "checking for gcc option to accept ISO C89... none needed\n",
      "checking for style of include used by make... GNU\n",
      "checking dependency style of gcc... none\n",
      "checking for g++... g++\n",
      "checking whether we are using the GNU C++ compiler... yes\n",
      "checking whether g++ accepts -g... yes\n",
      "checking dependency style of g++... none\n",
      "checking how to run the C preprocessor... gcc -E\n",
      "checking for grep that handles long lines and -e... /bin/grep\n",
      "checking for egrep... /bin/grep -E\n",
      "checking whether gcc needs -traditional... no\n",
      "checking whether make sets $(MAKE)... (cached) yes\n",
      "checking build system type... x86_64-unknown-linux-gnu\n",
      "checking host system type... x86_64-unknown-linux-gnu\n",
      "checking how to print strings... printf\n",
      "checking for a sed that does not truncate output... /bin/sed\n",
      "checking for fgrep... /bin/grep -F\n",
      "checking for ld used by gcc... /usr/bin/ld\n",
      "checking if the linker (/usr/bin/ld) is GNU ld... yes\n",
      "checking for BSD- or MS-compatible name lister (nm)... /usr/bin/nm -B\n",
      "checking the name lister (/usr/bin/nm -B) interface... BSD nm\n",
      "checking whether ln -s works... yes\n",
      "checking the maximum length of command line arguments... 1572864\n",
      "checking whether the shell understands some XSI constructs... yes\n",
      "checking whether the shell understands \"+=\"... yes\n",
      "checking how to convert x86_64-unknown-linux-gnu file names to x86_64-unknown-linux-gnu format... func_convert_file_noop\n",
      "checking how to convert x86_64-unknown-linux-gnu file names to toolchain format... func_convert_file_noop\n",
      "checking for /usr/bin/ld option to reload object files... -r\n",
      "checking for objdump... objdump\n",
      "checking how to recognize dependent libraries... pass_all\n",
      "checking for dlltool... dlltool\n",
      "checking how to associate runtime and link libraries... printf %s\\n\n",
      "checking for ar... ar\n",
      "checking for archiver @FILE support... @\n",
      "checking for strip... strip\n",
      "checking for ranlib... ranlib\n",
      "checking command to parse /usr/bin/nm -B output from gcc object... ok\n",
      "checking for sysroot... no\n",
      "./configure: line 7378: /usr/bin/file: No such file or directory\n",
      "checking for mt... no\n",
      "checking if : is a manifest tool... no\n",
      "checking for ANSI C header files... yes\n",
      "checking for sys/types.h... yes\n",
      "checking for sys/stat.h... yes\n",
      "checking for stdlib.h... yes\n",
      "checking for string.h... yes\n",
      "checking for memory.h... yes\n",
      "checking for strings.h... yes\n",
      "checking for inttypes.h... yes\n",
      "checking for stdint.h... yes\n",
      "checking for unistd.h... yes\n",
      "checking for dlfcn.h... yes\n",
      "checking for objdir... .libs\n",
      "checking if gcc supports -fno-rtti -fno-exceptions... no\n",
      "checking for gcc option to produce PIC... -fPIC -DPIC\n",
      "checking if gcc PIC flag -fPIC -DPIC works... yes\n",
      "checking if gcc static flag -static works... yes\n",
      "checking if gcc supports -c -o file.o... yes\n",
      "checking if gcc supports -c -o file.o... (cached) yes\n",
      "checking whether the gcc linker (/usr/bin/ld) supports shared libraries... yes\n",
      "checking whether -lc should be explicitly linked in... no\n",
      "checking dynamic linker characteristics... GNU/Linux ld.so\n",
      "checking how to hardcode library paths into programs... immediate\n",
      "checking whether stripping libraries is possible... yes\n",
      "checking if libtool supports shared libraries... yes\n",
      "checking whether to build shared libraries... yes\n",
      "checking whether to build static libraries... yes\n",
      "checking how to run the C++ preprocessor... g++ -E\n",
      "checking for ld used by g++... /usr/bin/ld\n",
      "checking if the linker (/usr/bin/ld) is GNU ld... yes\n",
      "checking whether the g++ linker (/usr/bin/ld) supports shared libraries... yes\n",
      "checking for g++ option to produce PIC... -fPIC -DPIC\n",
      "checking if g++ PIC flag -fPIC -DPIC works... yes\n",
      "checking if g++ static flag -static works... yes\n",
      "checking if g++ supports -c -o file.o... yes\n",
      "checking if g++ supports -c -o file.o... (cached) yes\n",
      "checking whether the g++ linker (/usr/bin/ld) supports shared libraries... yes\n",
      "checking dynamic linker characteristics... (cached) GNU/Linux ld.so\n",
      "checking how to hardcode library paths into programs... immediate\n",
      "checking for library containing strerror... none required\n",
      "checking whether byte ordering is bigendian... no\n",
      "checking for ld used by GCC... /usr/bin/ld\n",
      "checking if the linker (/usr/bin/ld) is GNU ld... yes\n",
      "checking for shared library run path origin... done\n",
      "checking for iconv... yes\n",
      "checking for working iconv... yes\n",
      "checking for iconv declaration... \n",
      "         extern size_t iconv (iconv_t cd, char * *inbuf, size_t *inbytesleft, char * *outbuf, size_t *outbytesleft);\n",
      "checking for ANSI C header files... (cached) yes\n",
      "checking for an ANSI C-conforming const... yes\n",
      "checking whether byte ordering is bigendian... (cached) no\n",
      "checking for string.h... (cached) yes\n",
      "checking for stdlib.h... (cached) yes\n",
      "checking for unistd.h... (cached) yes\n",
      "checking fcntl.h usability... yes\n",
      "checking fcntl.h presence... yes\n",
      "checking for fcntl.h... yes\n",
      "checking for stdint.h... (cached) yes\n",
      "checking for sys/stat.h... (cached) yes\n",
      "checking sys/mman.h usability... yes\n",
      "checking sys/mman.h presence... yes\n",
      "checking for sys/mman.h... yes\n",
      "checking sys/times.h usability... yes\n",
      "checking sys/times.h presence... yes\n",
      "checking for sys/times.h... yes\n",
      "checking for sys/types.h... (cached) yes\n",
      "checking dirent.h usability... yes\n",
      "checking dirent.h presence... yes\n",
      "checking for dirent.h... yes\n",
      "checking ctype.h usability... yes\n",
      "checking ctype.h presence... yes\n",
      "checking for ctype.h... yes\n",
      "checking for sys/types.h... (cached) yes\n",
      "checking io.h usability... no\n",
      "checking io.h presence... no\n",
      "checking for io.h... no\n",
      "checking windows.h usability... no\n",
      "checking windows.h presence... no\n",
      "checking for windows.h... no\n",
      "checking pthread.h usability... yes\n",
      "checking pthread.h presence... yes\n",
      "checking for pthread.h... yes\n",
      "checking for off_t... yes\n",
      "checking for size_t... yes\n",
      "checking size of char... 1\n",
      "checking size of short... 2\n",
      "checking size of int... 4\n",
      "checking size of long... 8\n",
      "checking size of long long... 8\n",
      "checking size of size_t... 8\n",
      "checking for size_t... (cached) yes\n",
      "checking for unsigned long long int... yes\n",
      "checking for stdlib.h... (cached) yes\n",
      "checking for unistd.h... (cached) yes\n",
      "checking for sys/param.h... yes\n",
      "checking for getpagesize... yes\n",
      "checking for working mmap... yes\n",
      "checking for main in -lstdc++... yes\n",
      "checking for pthread_create in -lpthread... yes\n",
      "checking for pthread_join in -lpthread... yes\n",
      "checking for getenv... yes\n",
      "checking for opendir... yes\n",
      "checking whether make is GNU Make... yes\n",
      "checking if g++ supports stl <vector> (required)... yes\n",
      "checking if g++ supports stl <list> (required)... yes\n",
      "checking if g++ supports stl <map> (required)... yes\n",
      "checking if g++ supports stl <set> (required)... yes\n",
      "checking if g++ supports stl <queue> (required)... yes\n",
      "checking if g++ supports stl <functional> (required)... yes\n",
      "checking if g++ supports stl <algorithm> (required)... yes\n",
      "checking if g++ supports stl <string> (required)... yes\n",
      "checking if g++ supports stl <iostream> (required)... yes\n",
      "checking if g++ supports stl <sstream> (required)... yes\n",
      "checking if g++ supports stl <fstream> (required)... yes\n",
      "checking if g++ supports template <class T> (required)... yes\n",
      "checking if g++ supports const_cast<> (required)... yes\n",
      "checking if g++ supports static_cast<> (required)... yes\n",
      "checking if g++ supports reinterpret_cast<> (required)... yes\n",
      "checking if g++ supports namespaces (required) ... yes\n",
      "checking if g++ supports __thread (optional)... yes\n",
      "checking if g++ supports template <class T> (required)... yes\n",
      "checking if g++ supports GCC native atomic operations (optional)... yes\n",
      "checking if g++ supports OSX native atomic operations (optional)... no\n",
      "checking if g++ environment provides all required features... yes\n",
      "configure: creating ./config.status\n",
      "config.status: creating Makefile\n",
      "config.status: creating src/Makefile\n",
      "config.status: creating src/Makefile.msvc\n",
      "config.status: creating man/Makefile\n",
      "config.status: creating doc/Makefile\n",
      "config.status: creating tests/Makefile\n",
      "config.status: creating swig/version.h\n",
      "config.status: creating mecab.iss\n",
      "config.status: creating mecab-config\n",
      "config.status: creating mecabrc\n",
      "config.status: creating config.h\n",
      "config.status: executing depfiles commands\n",
      "config.status: executing libtool commands\n",
      "config.status: executing default commands\n",
      "make  all-recursive\n",
      "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
      "Making all in src\n",
      "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
      "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o viterbi.lo viterbi.cpp\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c viterbi.cpp  -fPIC -DPIC -o .libs/viterbi.o\n",
      "In file included from \u001b[01m\u001b[Kviterbi.cpp:14:0\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[Kparam.h:30:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K'\u001b[01m\u001b[KTarget {anonymous}::lexical_cast(Source) [with Target = std::__cxx11::basic_string<char>; Source = std::__cxx11::basic_string<char>]\u001b[m\u001b[K' defined but not used [\u001b[01;35m\u001b[K-Wunused-function\u001b[m\u001b[K]\n",
      " std::string \u001b[01;35m\u001b[Klexical_cast<std::string, std::string>\u001b[m\u001b[K(std::string arg) {\n",
      "             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c viterbi.cpp -o viterbi.o >/dev/null 2>&1\n",
      "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o tagger.lo tagger.cpp\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c tagger.cpp  -fPIC -DPIC -o .libs/tagger.o\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c tagger.cpp -o tagger.o >/dev/null 2>&1\n",
      "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o utils.lo utils.cpp\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c utils.cpp  -fPIC -DPIC -o .libs/utils.o\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c utils.cpp -o utils.o >/dev/null 2>&1\n",
      "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o eval.lo eval.cpp\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c eval.cpp  -fPIC -DPIC -o .libs/eval.o\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c eval.cpp -o eval.o >/dev/null 2>&1\n",
      "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o iconv_utils.lo iconv_utils.cpp\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c iconv_utils.cpp  -fPIC -DPIC -o .libs/iconv_utils.o\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c iconv_utils.cpp -o iconv_utils.o >/dev/null 2>&1\n",
      "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o dictionary_rewriter.lo dictionary_rewriter.cpp\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_rewriter.cpp  -fPIC -DPIC -o .libs/dictionary_rewriter.o\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_rewriter.cpp -o dictionary_rewriter.o >/dev/null 2>&1\n",
      "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o dictionary_generator.lo dictionary_generator.cpp\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_generator.cpp  -fPIC -DPIC -o .libs/dictionary_generator.o\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_generator.cpp -o dictionary_generator.o >/dev/null 2>&1\n",
      "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o dictionary_compiler.lo dictionary_compiler.cpp\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_compiler.cpp  -fPIC -DPIC -o .libs/dictionary_compiler.o\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_compiler.cpp -o dictionary_compiler.o >/dev/null 2>&1\n",
      "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o context_id.lo context_id.cpp\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c context_id.cpp  -fPIC -DPIC -o .libs/context_id.o\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c context_id.cpp -o context_id.o >/dev/null 2>&1\n",
      "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o connector.lo connector.cpp\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c connector.cpp  -fPIC -DPIC -o .libs/connector.o\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c connector.cpp -o connector.o >/dev/null 2>&1\n",
      "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o nbest_generator.lo nbest_generator.cpp\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c nbest_generator.cpp  -fPIC -DPIC -o .libs/nbest_generator.o\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c nbest_generator.cpp -o nbest_generator.o >/dev/null 2>&1\n",
      "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o writer.lo writer.cpp\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c writer.cpp  -fPIC -DPIC -o .libs/writer.o\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c writer.cpp -o writer.o >/dev/null 2>&1\n",
      "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o string_buffer.lo string_buffer.cpp\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c string_buffer.cpp  -fPIC -DPIC -o .libs/string_buffer.o\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c string_buffer.cpp -o string_buffer.o >/dev/null 2>&1\n",
      "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o param.lo param.cpp\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c param.cpp  -fPIC -DPIC -o .libs/param.o\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c param.cpp -o param.o >/dev/null 2>&1\n",
      "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o tokenizer.lo tokenizer.cpp\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c tokenizer.cpp  -fPIC -DPIC -o .libs/tokenizer.o\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c tokenizer.cpp -o tokenizer.o >/dev/null 2>&1\n",
      "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o char_property.lo char_property.cpp\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c char_property.cpp  -fPIC -DPIC -o .libs/char_property.o\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c char_property.cpp -o char_property.o >/dev/null 2>&1\n",
      "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o dictionary.lo dictionary.cpp\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary.cpp  -fPIC -DPIC -o .libs/dictionary.o\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary.cpp -o dictionary.o >/dev/null 2>&1\n",
      "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o feature_index.lo feature_index.cpp\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c feature_index.cpp  -fPIC -DPIC -o .libs/feature_index.o\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c feature_index.cpp -o feature_index.o >/dev/null 2>&1\n",
      "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o lbfgs.lo lbfgs.cpp\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c lbfgs.cpp  -fPIC -DPIC -o .libs/lbfgs.o\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c lbfgs.cpp -o lbfgs.o >/dev/null 2>&1\n",
      "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o learner_tagger.lo learner_tagger.cpp\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c learner_tagger.cpp  -fPIC -DPIC -o .libs/learner_tagger.o\n",
      "\u001b[01m\u001b[Klearner_tagger.cpp:25:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K'\u001b[01m\u001b[Kchar* MeCab::{anonymous}::mystrdup(const string&)\u001b[m\u001b[K' defined but not used [\u001b[01;35m\u001b[K-Wunused-function\u001b[m\u001b[K]\n",
      " char *\u001b[01;35m\u001b[Kmystrdup\u001b[m\u001b[K(const std::string &str) {\n",
      "       \u001b[01;35m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c learner_tagger.cpp -o learner_tagger.o >/dev/null 2>&1\n",
      "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o learner.lo learner.cpp\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c learner.cpp  -fPIC -DPIC -o .libs/learner.o\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c learner.cpp -o learner.o >/dev/null 2>&1\n",
      "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o libmecab.lo libmecab.cpp\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c libmecab.cpp  -fPIC -DPIC -o .libs/libmecab.o\n",
      "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c libmecab.cpp -o libmecab.o >/dev/null 2>&1\n",
      "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall  -no-undefined -version-info 2:0:0  -o libmecab.la -rpath /usr/local/lib viterbi.lo tagger.lo utils.lo eval.lo iconv_utils.lo dictionary_rewriter.lo dictionary_generator.lo dictionary_compiler.lo context_id.lo connector.lo nbest_generator.lo writer.lo string_buffer.lo param.lo tokenizer.lo char_property.lo dictionary.lo feature_index.lo lbfgs.lo learner_tagger.lo learner.lo libmecab.lo  -lpthread -lpthread  -lstdc++ \n",
      "libtool: link: g++  -fPIC -DPIC -shared -nostdlib /usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu/crti.o /usr/lib/gcc/x86_64-linux-gnu/7/crtbeginS.o  .libs/viterbi.o .libs/tagger.o .libs/utils.o .libs/eval.o .libs/iconv_utils.o .libs/dictionary_rewriter.o .libs/dictionary_generator.o .libs/dictionary_compiler.o .libs/context_id.o .libs/connector.o .libs/nbest_generator.o .libs/writer.o .libs/string_buffer.o .libs/param.o .libs/tokenizer.o .libs/char_property.o .libs/dictionary.o .libs/feature_index.o .libs/lbfgs.o .libs/learner_tagger.o .libs/learner.o .libs/libmecab.o   -lpthread -L/usr/lib/gcc/x86_64-linux-gnu/7 -L/usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu -L/usr/lib/gcc/x86_64-linux-gnu/7/../../../../lib -L/lib/x86_64-linux-gnu -L/lib/../lib -L/usr/lib/x86_64-linux-gnu -L/usr/lib/../lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/gcc/x86_64-linux-gnu/7/../../.. -lstdc++ -lm -lc -lgcc_s /usr/lib/gcc/x86_64-linux-gnu/7/crtendS.o /usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu/crtn.o  -O3   -Wl,-soname -Wl,libmecab.so.2 -o .libs/libmecab.so.2.0.0\n",
      "libtool: link: (cd \".libs\" && rm -f \"libmecab.so.2\" && ln -s \"libmecab.so.2.0.0\" \"libmecab.so.2\")\n",
      "libtool: link: (cd \".libs\" && rm -f \"libmecab.so\" && ln -s \"libmecab.so.2.0.0\" \"libmecab.so\")\n",
      "libtool: link: ar cru .libs/libmecab.a  viterbi.o tagger.o utils.o eval.o iconv_utils.o dictionary_rewriter.o dictionary_generator.o dictionary_compiler.o context_id.o connector.o nbest_generator.o writer.o string_buffer.o param.o tokenizer.o char_property.o dictionary.o feature_index.o lbfgs.o learner_tagger.o learner.o libmecab.o\n",
      "ar: `u' modifier ignored since `D' is the default (see `U')\n",
      "libtool: link: ranlib .libs/libmecab.a\n",
      "libtool: link: ( cd \".libs\" && rm -f \"libmecab.la\" && ln -s \"../libmecab.la\" \"libmecab.la\" )\n",
      "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab.o mecab.cpp\n",
      "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab mecab.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
      "libtool: link: g++ -O3 -Wall -o .libs/mecab mecab.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
      "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-dict-index.o mecab-dict-index.cpp\n",
      "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-dict-index mecab-dict-index.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
      "libtool: link: g++ -O3 -Wall -o .libs/mecab-dict-index mecab-dict-index.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
      "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-dict-gen.o mecab-dict-gen.cpp\n",
      "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-dict-gen mecab-dict-gen.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
      "libtool: link: g++ -O3 -Wall -o .libs/mecab-dict-gen mecab-dict-gen.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
      "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-cost-train.o mecab-cost-train.cpp\n",
      "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-cost-train mecab-cost-train.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
      "libtool: link: g++ -O3 -Wall -o .libs/mecab-cost-train mecab-cost-train.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
      "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-system-eval.o mecab-system-eval.cpp\n",
      "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-system-eval mecab-system-eval.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
      "libtool: link: g++ -O3 -Wall -o .libs/mecab-system-eval mecab-system-eval.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
      "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-test-gen.o mecab-test-gen.cpp\n",
      "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-test-gen mecab-test-gen.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
      "libtool: link: g++ -O3 -Wall -o .libs/mecab-test-gen mecab-test-gen.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
      "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
      "Making all in man\n",
      "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
      "make[2]: Nothing to be done for 'all'.\n",
      "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
      "Making all in doc\n",
      "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
      "make[2]: Nothing to be done for 'all'.\n",
      "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
      "Making all in tests\n",
      "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
      "make[2]: Nothing to be done for 'all'.\n",
      "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
      "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
      "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
      "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
      "Making check in src\n",
      "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
      "make[1]: Nothing to be done for 'check'.\n",
      "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
      "Making check in man\n",
      "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
      "make[1]: Nothing to be done for 'check'.\n",
      "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
      "Making check in doc\n",
      "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
      "make[1]: Nothing to be done for 'check'.\n",
      "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
      "Making check in tests\n",
      "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
      "make  check-TESTS\n",
      "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
      "./pos-id.def is not found. minimum setting is used\n",
      "reading ./unk.def ... 2\n",
      "emitting double-array: 100% |###########################################| \n",
      "./model.def is not found. skipped.\n",
      "./pos-id.def is not found. minimum setting is used\n",
      "reading ./dic.csv ... 177\n",
      "emitting double-array: 100% |###########################################| \n",
      "reading ./matrix.def ... 178x178\n",
      "emitting matrix      : 100% |###########################################| \n",
      "\n",
      "done!\n",
      "./pos-id.def is not found. minimum setting is used\n",
      "reading ./unk.def ... 2\n",
      "emitting double-array: 100% |###########################################| \n",
      "./model.def is not found. skipped.\n",
      "./pos-id.def is not found. minimum setting is used\n",
      "reading ./dic.csv ... 83\n",
      "emitting double-array: 100% |###########################################| \n",
      "reading ./matrix.def ... 84x84\n",
      "emitting matrix      : 100% |###########################################| \n",
      "\n",
      "done!\n",
      "./pos-id.def is not found. minimum setting is used\n",
      "reading ./unk.def ... 2\n",
      "emitting double-array: 100% |###########################################| \n",
      "./model.def is not found. skipped.\n",
      "./pos-id.def is not found. minimum setting is used\n",
      "reading ./dic.csv ... 450\n",
      "emitting double-array: 100% |###########################################| \n",
      "reading ./matrix.def ... 1x1\n",
      "\n",
      "done!\n",
      "./pos-id.def is not found. minimum setting is used\n",
      "reading ./unk.def ... 2\n",
      "emitting double-array: 100% |###########################################| \n",
      "./model.def is not found. skipped.\n",
      "./pos-id.def is not found. minimum setting is used\n",
      "reading ./dic.csv ... 162\n",
      "emitting double-array: 100% |###########################################| \n",
      "reading ./matrix.def ... 3x3\n",
      "emitting matrix      : 100% |###########################################| \n",
      "\n",
      "done!\n",
      "./pos-id.def is not found. minimum setting is used\n",
      "reading ./unk.def ... 2\n",
      "emitting double-array: 100% |###########################################| \n",
      "./model.def is not found. skipped.\n",
      "./pos-id.def is not found. minimum setting is used\n",
      "reading ./dic.csv ... 4\n",
      "emitting double-array: 100% |###########################################| \n",
      "reading ./matrix.def ... 1x1\n",
      "\n",
      "done!\n",
      "./pos-id.def is not found. minimum setting is used\n",
      "reading ./unk.def ... 11\n",
      "emitting double-array: 100% |###########################################| \n",
      "./model.def is not found. skipped.\n",
      "./pos-id.def is not found. minimum setting is used\n",
      "reading ./dic.csv ... 1\n",
      "reading ./matrix.def ... 1x1\n",
      "\n",
      "done!\n",
      "./pos-id.def is not found. minimum setting is used\n",
      "reading ./unk.def ... 2\n",
      "emitting double-array: 100% |###########################################| \n",
      "./model.def is not found. skipped.\n",
      "./pos-id.def is not found. minimum setting is used\n",
      "reading ./dic.csv ... 1\n",
      "reading ./matrix.def ... 1x1\n",
      "\n",
      "done!\n",
      "PASS: run-dics.sh\n",
      "PASS: run-eval.sh\n",
      "seed/pos-id.def is not found. minimum setting is used\n",
      "reading seed/unk.def ... 40\n",
      "emitting double-array: 100% |###########################################| \n",
      "seed/model.def is not found. skipped.\n",
      "seed/pos-id.def is not found. minimum setting is used\n",
      "reading seed/dic.csv ... 4335\n",
      "emitting double-array: 100% |###########################################| \n",
      "reading seed/matrix.def ... 1x1\n",
      "\n",
      "done!\n",
      "reading corpus ...\n",
      "Number of sentences: 34\n",
      "Number of features:  64108\n",
      "eta:                 0.00005\n",
      "freq:                1\n",
      "eval-size:           6\n",
      "unk-eval-size:       4\n",
      "threads:             1\n",
      "charset:             EUC-JP\n",
      "C(sigma^2):          1.00000\n",
      "\n",
      "iter=0 err=1.00000 F=0.35771 target=2406.28355 diff=1.00000\n",
      "iter=1 err=0.97059 F=0.65652 target=1484.25231 diff=0.38318\n",
      "iter=2 err=0.91176 F=0.79331 target=863.32765 diff=0.41834\n",
      "iter=3 err=0.85294 F=0.89213 target=596.72480 diff=0.30881\n",
      "iter=4 err=0.61765 F=0.95467 target=336.30744 diff=0.43641\n",
      "iter=5 err=0.50000 F=0.96702 target=246.53039 diff=0.26695\n",
      "iter=6 err=0.35294 F=0.95472 target=188.93963 diff=0.23361\n",
      "iter=7 err=0.20588 F=0.99106 target=168.62665 diff=0.10751\n",
      "iter=8 err=0.05882 F=0.99777 target=158.64865 diff=0.05917\n",
      "iter=9 err=0.08824 F=0.99665 target=154.14530 diff=0.02839\n",
      "iter=10 err=0.08824 F=0.99665 target=151.94257 diff=0.01429\n",
      "iter=11 err=0.02941 F=0.99888 target=147.20825 diff=0.03116\n",
      "iter=12 err=0.00000 F=1.00000 target=147.34956 diff=0.00096\n",
      "iter=13 err=0.02941 F=0.99888 target=146.32592 diff=0.00695\n",
      "iter=14 err=0.00000 F=1.00000 target=145.77299 diff=0.00378\n",
      "iter=15 err=0.02941 F=0.99888 target=145.24641 diff=0.00361\n",
      "iter=16 err=0.00000 F=1.00000 target=144.96490 diff=0.00194\n",
      "iter=17 err=0.02941 F=0.99888 target=144.90246 diff=0.00043\n",
      "iter=18 err=0.00000 F=1.00000 target=144.75959 diff=0.00099\n",
      "iter=19 err=0.00000 F=1.00000 target=144.71727 diff=0.00029\n",
      "iter=20 err=0.00000 F=1.00000 target=144.66337 diff=0.00037\n",
      "iter=21 err=0.00000 F=1.00000 target=144.61349 diff=0.00034\n",
      "iter=22 err=0.00000 F=1.00000 target=144.62987 diff=0.00011\n",
      "iter=23 err=0.00000 F=1.00000 target=144.60060 diff=0.00020\n",
      "iter=24 err=0.00000 F=1.00000 target=144.59125 diff=0.00006\n",
      "iter=25 err=0.00000 F=1.00000 target=144.58619 diff=0.00004\n",
      "iter=26 err=0.00000 F=1.00000 target=144.58219 diff=0.00003\n",
      "iter=27 err=0.00000 F=1.00000 target=144.58059 diff=0.00001\n",
      "\n",
      "Done! writing model file ... \n",
      "model-ipadic.c1.0.f1.model is not a binary model. reopen it as text mode...\n",
      "reading seed/unk.def ... 40\n",
      "reading seed/dic.csv ... 4335\n",
      "emitting model-ipadic.c1.0.f1.dic/left-id.def/ model-ipadic.c1.0.f1.dic/right-id.def\n",
      "emitting model-ipadic.c1.0.f1.dic/unk.def ... 40\n",
      "emitting model-ipadic.c1.0.f1.dic/dic.csv ... 4335\n",
      "emitting matrix      : 100% |###########################################| \n",
      "copying seed/char.def to model-ipadic.c1.0.f1.dic/char.def\n",
      "copying seed/rewrite.def to model-ipadic.c1.0.f1.dic/rewrite.def\n",
      "copying seed/dicrc to model-ipadic.c1.0.f1.dic/dicrc\n",
      "copying seed/feature.def to model-ipadic.c1.0.f1.dic/feature.def\n",
      "copying model-ipadic.c1.0.f1.model to model-ipadic.c1.0.f1.dic/model.def\n",
      "\n",
      "done!\n",
      "model-ipadic.c1.0.f1.dic/pos-id.def is not found. minimum setting is used\n",
      "reading model-ipadic.c1.0.f1.dic/unk.def ... 40\n",
      "emitting double-array: 100% |###########################################| \n",
      "model-ipadic.c1.0.f1.dic/pos-id.def is not found. minimum setting is used\n",
      "reading model-ipadic.c1.0.f1.dic/dic.csv ... 4335\n",
      "emitting double-array: 100% |###########################################| \n",
      "reading model-ipadic.c1.0.f1.dic/matrix.def ... 346x346\n",
      "emitting matrix      : 100% |###########################################| \n",
      "\n",
      "done!\n",
      "              precision          recall         F\n",
      "LEVEL 0:    12.8959(57/442) 11.8998(57/479) 12.3779\n",
      "LEVEL 1:    12.2172(54/442) 11.2735(54/479) 11.7264\n",
      "LEVEL 2:    11.7647(52/442) 10.8559(52/479) 11.2921\n",
      "LEVEL 4:    11.7647(52/442) 10.8559(52/479) 11.2921\n",
      "PASS: run-cost-train.sh\n",
      "==================\n",
      "All 3 tests passed\n",
      "==================\n",
      "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
      "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
      "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
      "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
      "Making install in src\n",
      "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
      "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
      "test -z \"/usr/local/lib\" || /bin/mkdir -p \"/usr/local/lib\"\n",
      " /bin/bash ../libtool   --mode=install /usr/bin/install -c   libmecab.la '/usr/local/lib'\n",
      "libtool: install: /usr/bin/install -c .libs/libmecab.so.2.0.0 /usr/local/lib/libmecab.so.2.0.0\n",
      "libtool: install: (cd /usr/local/lib && { ln -s -f libmecab.so.2.0.0 libmecab.so.2 || { rm -f libmecab.so.2 && ln -s libmecab.so.2.0.0 libmecab.so.2; }; })\n",
      "libtool: install: (cd /usr/local/lib && { ln -s -f libmecab.so.2.0.0 libmecab.so || { rm -f libmecab.so && ln -s libmecab.so.2.0.0 libmecab.so; }; })\n",
      "libtool: install: /usr/bin/install -c .libs/libmecab.lai /usr/local/lib/libmecab.la\n",
      "libtool: install: /usr/bin/install -c .libs/libmecab.a /usr/local/lib/libmecab.a\n",
      "libtool: install: chmod 644 /usr/local/lib/libmecab.a\n",
      "libtool: install: ranlib /usr/local/lib/libmecab.a\n",
      "libtool: finish: PATH=\"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin:/sbin\" ldconfig -n /usr/local/lib\n",
      "----------------------------------------------------------------------\n",
      "Libraries have been installed in:\n",
      "   /usr/local/lib\n",
      "\n",
      "If you ever happen to want to link against installed libraries\n",
      "in a given directory, LIBDIR, you must either use libtool, and\n",
      "specify the full pathname of the library, or use the `-LLIBDIR'\n",
      "flag during linking and do at least one of the following:\n",
      "   - add LIBDIR to the `LD_LIBRARY_PATH' environment variable\n",
      "     during execution\n",
      "   - add LIBDIR to the `LD_RUN_PATH' environment variable\n",
      "     during linking\n",
      "   - use the `-Wl,-rpath -Wl,LIBDIR' linker flag\n",
      "   - have your system administrator add LIBDIR to `/etc/ld.so.conf'\n",
      "\n",
      "See any operating system documentation about shared libraries for\n",
      "more information, such as the ld(1) and ld.so(8) manual pages.\n",
      "----------------------------------------------------------------------\n",
      "test -z \"/usr/local/bin\" || /bin/mkdir -p \"/usr/local/bin\"\n",
      "  /bin/bash ../libtool   --mode=install /usr/bin/install -c mecab '/usr/local/bin'\n",
      "libtool: install: /usr/bin/install -c .libs/mecab /usr/local/bin/mecab\n",
      "test -z \"/usr/local/libexec/mecab\" || /bin/mkdir -p \"/usr/local/libexec/mecab\"\n",
      "  /bin/bash ../libtool   --mode=install /usr/bin/install -c mecab-dict-index mecab-dict-gen mecab-cost-train mecab-system-eval mecab-test-gen '/usr/local/libexec/mecab'\n",
      "libtool: install: /usr/bin/install -c .libs/mecab-dict-index /usr/local/libexec/mecab/mecab-dict-index\n",
      "libtool: install: /usr/bin/install -c .libs/mecab-dict-gen /usr/local/libexec/mecab/mecab-dict-gen\n",
      "libtool: install: /usr/bin/install -c .libs/mecab-cost-train /usr/local/libexec/mecab/mecab-cost-train\n",
      "libtool: install: /usr/bin/install -c .libs/mecab-system-eval /usr/local/libexec/mecab/mecab-system-eval\n",
      "libtool: install: /usr/bin/install -c .libs/mecab-test-gen /usr/local/libexec/mecab/mecab-test-gen\n",
      "test -z \"/usr/local/include\" || /bin/mkdir -p \"/usr/local/include\"\n",
      " /usr/bin/install -c -m 644 mecab.h '/usr/local/include'\n",
      "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
      "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
      "Making install in man\n",
      "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
      "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
      "make[2]: Nothing to be done for 'install-exec-am'.\n",
      "test -z \"/usr/local/share/man/man1\" || /bin/mkdir -p \"/usr/local/share/man/man1\"\n",
      " /usr/bin/install -c -m 644 mecab.1 '/usr/local/share/man/man1'\n",
      "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
      "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
      "Making install in doc\n",
      "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
      "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
      "make[2]: Nothing to be done for 'install-exec-am'.\n",
      "make[2]: Nothing to be done for 'install-data-am'.\n",
      "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
      "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
      "Making install in tests\n",
      "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
      "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
      "make[2]: Nothing to be done for 'install-exec-am'.\n",
      "make[2]: Nothing to be done for 'install-data-am'.\n",
      "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
      "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
      "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
      "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
      "test -z \"/usr/local/bin\" || /bin/mkdir -p \"/usr/local/bin\"\n",
      " /usr/bin/install -c mecab-config '/usr/local/bin'\n",
      "test -z \"/usr/local/etc\" || /bin/mkdir -p \"/usr/local/etc\"\n",
      " /usr/bin/install -c -m 644 mecabrc '/usr/local/etc'\n",
      "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
      "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
      "Install mecab-ko-dic\n",
      "Install mecab-ko-dic\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 47.4M  100 47.4M    0     0  15.9M      0  0:00:02  0:00:02 --:--:-- 20.4M\n",
      "mecab-ko-dic-2.1.1-20180720/\n",
      "mecab-ko-dic-2.1.1-20180720/configure\n",
      "mecab-ko-dic-2.1.1-20180720/COPYING\n",
      "mecab-ko-dic-2.1.1-20180720/autogen.sh\n",
      "mecab-ko-dic-2.1.1-20180720/Place-station.csv\n",
      "mecab-ko-dic-2.1.1-20180720/NNG.csv\n",
      "mecab-ko-dic-2.1.1-20180720/README\n",
      "mecab-ko-dic-2.1.1-20180720/EF.csv\n",
      "mecab-ko-dic-2.1.1-20180720/MAG.csv\n",
      "mecab-ko-dic-2.1.1-20180720/Preanalysis.csv\n",
      "mecab-ko-dic-2.1.1-20180720/NNB.csv\n",
      "mecab-ko-dic-2.1.1-20180720/Person-actor.csv\n",
      "mecab-ko-dic-2.1.1-20180720/VV.csv\n",
      "mecab-ko-dic-2.1.1-20180720/Makefile.in\n",
      "mecab-ko-dic-2.1.1-20180720/matrix.def\n",
      "mecab-ko-dic-2.1.1-20180720/EC.csv\n",
      "mecab-ko-dic-2.1.1-20180720/NNBC.csv\n",
      "mecab-ko-dic-2.1.1-20180720/clean\n",
      "mecab-ko-dic-2.1.1-20180720/ChangeLog\n",
      "mecab-ko-dic-2.1.1-20180720/J.csv\n",
      "mecab-ko-dic-2.1.1-20180720/.keep\n",
      "mecab-ko-dic-2.1.1-20180720/feature.def\n",
      "mecab-ko-dic-2.1.1-20180720/Foreign.csv\n",
      "mecab-ko-dic-2.1.1-20180720/XPN.csv\n",
      "mecab-ko-dic-2.1.1-20180720/EP.csv\n",
      "mecab-ko-dic-2.1.1-20180720/NR.csv\n",
      "mecab-ko-dic-2.1.1-20180720/left-id.def\n",
      "mecab-ko-dic-2.1.1-20180720/Place.csv\n",
      "mecab-ko-dic-2.1.1-20180720/Symbol.csv\n",
      "mecab-ko-dic-2.1.1-20180720/dicrc\n",
      "mecab-ko-dic-2.1.1-20180720/NP.csv\n",
      "mecab-ko-dic-2.1.1-20180720/ETM.csv\n",
      "mecab-ko-dic-2.1.1-20180720/IC.csv\n",
      "mecab-ko-dic-2.1.1-20180720/Place-address.csv\n",
      "mecab-ko-dic-2.1.1-20180720/Group.csv\n",
      "mecab-ko-dic-2.1.1-20180720/model.def\n",
      "mecab-ko-dic-2.1.1-20180720/XSN.csv\n",
      "mecab-ko-dic-2.1.1-20180720/INSTALL\n",
      "mecab-ko-dic-2.1.1-20180720/rewrite.def\n",
      "mecab-ko-dic-2.1.1-20180720/Inflect.csv\n",
      "mecab-ko-dic-2.1.1-20180720/configure.ac\n",
      "mecab-ko-dic-2.1.1-20180720/NNP.csv\n",
      "mecab-ko-dic-2.1.1-20180720/CoinedWord.csv\n",
      "mecab-ko-dic-2.1.1-20180720/XSV.csv\n",
      "mecab-ko-dic-2.1.1-20180720/pos-id.def\n",
      "mecab-ko-dic-2.1.1-20180720/Makefile.am\n",
      "mecab-ko-dic-2.1.1-20180720/unk.def\n",
      "mecab-ko-dic-2.1.1-20180720/missing\n",
      "mecab-ko-dic-2.1.1-20180720/VCP.csv\n",
      "mecab-ko-dic-2.1.1-20180720/install-sh\n",
      "mecab-ko-dic-2.1.1-20180720/Hanja.csv\n",
      "mecab-ko-dic-2.1.1-20180720/MAJ.csv\n",
      "mecab-ko-dic-2.1.1-20180720/XSA.csv\n",
      "mecab-ko-dic-2.1.1-20180720/Wikipedia.csv\n",
      "mecab-ko-dic-2.1.1-20180720/tools/\n",
      "mecab-ko-dic-2.1.1-20180720/tools/add-userdic.sh\n",
      "mecab-ko-dic-2.1.1-20180720/tools/mecab-bestn.sh\n",
      "mecab-ko-dic-2.1.1-20180720/tools/convert_for_using_store.sh\n",
      "mecab-ko-dic-2.1.1-20180720/user-dic/\n",
      "mecab-ko-dic-2.1.1-20180720/user-dic/nnp.csv\n",
      "mecab-ko-dic-2.1.1-20180720/user-dic/place.csv\n",
      "mecab-ko-dic-2.1.1-20180720/user-dic/person.csv\n",
      "mecab-ko-dic-2.1.1-20180720/user-dic/README.md\n",
      "mecab-ko-dic-2.1.1-20180720/NorthKorea.csv\n",
      "mecab-ko-dic-2.1.1-20180720/VX.csv\n",
      "mecab-ko-dic-2.1.1-20180720/right-id.def\n",
      "mecab-ko-dic-2.1.1-20180720/VA.csv\n",
      "mecab-ko-dic-2.1.1-20180720/char.def\n",
      "mecab-ko-dic-2.1.1-20180720/NEWS\n",
      "mecab-ko-dic-2.1.1-20180720/MM.csv\n",
      "mecab-ko-dic-2.1.1-20180720/ETN.csv\n",
      "mecab-ko-dic-2.1.1-20180720/AUTHORS\n",
      "mecab-ko-dic-2.1.1-20180720/Person.csv\n",
      "mecab-ko-dic-2.1.1-20180720/XR.csv\n",
      "mecab-ko-dic-2.1.1-20180720/VCN.csv\n",
      "Looking in current directory for macros.\n",
      "configure.ac:2: warning: AM_INIT_AUTOMAKE: two- and three-arguments forms are deprecated.  For more info, see:\n",
      "configure.ac:2: http://www.gnu.org/software/automake/manual/automake.html#Modernize-AM_005fINIT_005fAUTOMAKE-invocation\n",
      "checking for a BSD-compatible install... /usr/bin/install -c\n",
      "checking whether build environment is sane... yes\n",
      "/tmp/mecab-ko-dic-2.1.1-20180720/missing: Unknown `--is-lightweight' option\n",
      "Try `/tmp/mecab-ko-dic-2.1.1-20180720/missing --help' for more information\n",
      "configure: WARNING: 'missing' script is too old or missing\n",
      "checking for a thread-safe mkdir -p... /bin/mkdir -p\n",
      "checking for gawk... no\n",
      "checking for mawk... mawk\n",
      "checking whether make sets $(MAKE)... yes\n",
      "checking whether make supports nested variables... yes\n",
      "checking for mecab-config... /usr/local/bin/mecab-config\n",
      "checking that generated files are newer than configure... done\n",
      "configure: creating ./config.status\n",
      "config.status: creating Makefile\n",
      "/usr/local/lib\n",
      "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
      "\n",
      "/usr/local/libexec/mecab/mecab-dict-index -d . -o . -f UTF-8 -t UTF-8\n",
      "reading ./unk.def ... 13\n",
      "emitting double-array: 100% |###########################################| \n",
      "reading ./XSV.csv ... 23\n",
      "reading ./EC.csv ... 2547\n",
      "reading ./EP.csv ... 51\n",
      "reading ./MM.csv ... 453\n",
      "reading ./Group.csv ... 3176\n",
      "reading ./Foreign.csv ... 11690\n",
      "reading ./NNP.csv ... 2371\n",
      "reading ./Symbol.csv ... 16\n",
      "reading ./XPN.csv ... 83\n",
      "reading ./IC.csv ... 1305\n",
      "reading ./Inflect.csv ... 44820\n",
      "reading ./ETN.csv ... 14\n",
      "reading ./MAG.csv ... 14242\n",
      "reading ./Place.csv ... 30303\n",
      "reading ./NP.csv ... 342\n",
      "reading ./NorthKorea.csv ... 3\n",
      "reading ./Place-station.csv ... 1145\n",
      "reading ./XSA.csv ... 19\n",
      "reading ./NNB.csv ... 140\n",
      "reading ./Person.csv ... 196459\n",
      "reading ./Wikipedia.csv ... 36762\n",
      "reading ./NNG.csv ... 208524\n",
      "reading ./J.csv ... 416\n",
      "reading ./VV.csv ... 7331\n",
      "reading ./ETM.csv ... 133\n",
      "reading ./XR.csv ... 3637\n",
      "reading ./Preanalysis.csv ... 5\n",
      "reading ./EF.csv ... 1820\n",
      "reading ./VCN.csv ... 7\n",
      "reading ./Place-address.csv ... 19301\n",
      "reading ./NNBC.csv ... 677\n",
      "reading ./CoinedWord.csv ... 148\n",
      "reading ./Hanja.csv ... 125750\n",
      "reading ./MAJ.csv ... 240\n",
      "reading ./XSN.csv ... 124\n",
      "reading ./Person-actor.csv ... 99230\n",
      "reading ./VA.csv ... 2360\n",
      "reading ./VCP.csv ... 9\n",
      "reading ./NR.csv ... 482\n",
      "reading ./VX.csv ... 125\n",
      "emitting double-array: 100% |###########################################| \n",
      "reading ./matrix.def ... 3822x2693\n",
      "emitting matrix      : 100% |###########################################| \n",
      "\n",
      "done!\n",
      "echo To enable dictionary, rewrite /usr/local/etc/mecabrc as \\\"dicdir = /usr/local/lib/mecab/dic/mecab-ko-dic\\\"\n",
      "To enable dictionary, rewrite /usr/local/etc/mecabrc as \"dicdir = /usr/local/lib/mecab/dic/mecab-ko-dic\"\n",
      "make[1]: Entering directory '/tmp/mecab-ko-dic-2.1.1-20180720'\n",
      "make[1]: Nothing to be done for 'install-exec-am'.\n",
      " /bin/mkdir -p '/usr/local/lib/mecab/dic/mecab-ko-dic'\n",
      " /usr/bin/install -c -m 644 model.bin matrix.bin char.bin sys.dic unk.dic left-id.def right-id.def rewrite.def pos-id.def dicrc '/usr/local/lib/mecab/dic/mecab-ko-dic'\n",
      "make[1]: Leaving directory '/tmp/mecab-ko-dic-2.1.1-20180720'\n",
      "Install mecab-python\n",
      "/tmp /tmp/mecab-ko-dic-2.1.1-20180720\n",
      "Cloning into 'mecab-python-0.996'...\n",
      "remote: Counting objects: 17, done.\u001b[K\n",
      "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
      "remote: Total 17 (delta 3), reused 0 (delta 0)\u001b[K\n",
      "Unpacking objects: 100% (17/17), done.\n",
      "/tmp/mecab-ko-dic-2.1.1-20180720\n",
      "Processing /tmp/mecab-python-0.996\n",
      "Building wheels for collected packages: mecab-python\n",
      "  Building wheel for mecab-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for mecab-python: filename=mecab_python-0.996_ko_0.9.2-cp36-cp36m-linux_x86_64.whl size=140573 sha256=e004838ba5a96384c7e55ba05227d51d445fb7fdc9c20202e8ae88c40c2e000b\n",
      "  Stored in directory: /root/.cache/pip/wheels/99/75/a6/e9e73a1dbd73579383644942ef18a6d17ad728a3052a1147fb\n",
      "Successfully built mecab-python\n",
      "Installing collected packages: mecab-python\n",
      "Successfully installed mecab-python-0.996-ko-0.9.2\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# !sudo apt-get install g++ openjdk-7-jdk # Install Java 1.7+\n",
    "# !sudo apt-get install python-dev; pip install konlpy     # Python 2.x\n",
    "!sudo apt-get install python3-dev; pip3 install konlpy   # Python 3.x\n",
    "!sudo apt-get install curl\n",
    "!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "piKvCjRvgHFE"
   },
   "source": [
    "# 9-1 Luhn Summarizer\n",
    "\n",
    "http://courses.ischool.berkeley.edu/i256/f06/papers/luhn58.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OFwBVB3ogZeF"
   },
   "source": [
    "Hans Peter Luhn\n",
    "\n",
    "https://en.wikipedia.org/wiki/Hans_Peter_Luhn\n",
    "\n",
    " Hans Peter Luhn은 공학과 정보과학에서의 개척 작업으로 \"정보 검색의 아버지\"로 알려져 있다. 그는 표제어가 문맥에 포함된 채 배열된 색인(KWIC : keyword-in-context) 개발, 정보 선택 제공(SDI), 완전 텍스트 프로세싱, 자동 발췌(요약), 단어 시소로스의 최초 현대식 사용으로 신뢰를 얻었다. 오늘날 파생된 지식 대부분에는 KWIC 색인이 있으며 과학의 모든 분야에 SDI시스템이 있다. \n",
    "\n",
    "\n",
    " Luhn은 1896년 7월 1일 독일 바르멘에서 태어났다. 아버지가 그 당시 유명한 인쇄업자였으므로, 스위스에서 인쇄업을 배웠다. 어렸을 때무터 그는 창조성이 뛰어난 재능을 보였으며, 기술적 문제, 물리학, 통계학에 관심을 보였다. 그러나 1차 세계대전으로 독일군 통신장교로 복역(1915년1917년)하면서 프랑스 터키 루마니아 불가리아 등지로 옮겨 다녀야만 했다. 1차 대전 이후 그는 스위스의 Gallen 교회 Schweizwrische handels Hochschule로 돌아와 기술, 물리학, 회계분야의 수업을 들었다. 그 후, Luhn은 그리스에서 못다한 공부에 전념했으며, 더블부기기계(Duble-Entry Bookeeping Machine : 카드 대장에 대변기입과 차변 기입을 기록할 수 있는 것)를 발명하였다. 그는 또 Hollerith tabulating/recording machine에 정통했고, 천공카드에서 문자 숫자를 나타내는 장치의 사용을 증가시키게 했다. 1920년부터 1930년까지는 10개의 특허권을 획득하여 그의 탁월한 능력을 보여주었다. 그것들중에 루노메터(Lunometer : 직물의 실길이를 계산하는데 쓰이는 장치)는 지금도 사용되고 있다.\n",
    "\n",
    "\n",
    " 1920년까지 그는 직물 공장에서 일하기 시작했다. 그는 직물 공장의 사업확장을 위해 뉴잉글랜드에서 1924년 미국으로 가게 되었다. 그러나 회사가 곧 파산하였고 Luhn은 직장없이 뉴욕에 남게 되었다. 그는 은행에서 일을 하였고 곧 뉴욕 월스트리트에 소재한 국제어음은행(International Acceptance Bank)에서 재정담당관으로 승진하였다. \n",
    "\n",
    "\n",
    " 1933년 Luhn은 자사인 공학회사 H.P. Luhn & Association을 설립하였고 8년간 자문기술자로 일했다. 1941년 Luhn은 IBM에서 수석 연구기술자로 참여하였고 이후에 정보검색연구 관리자로 일했다. Luhn이 IBM에서 새로운 아이디어를 지속적으로 내놓고 문제를 다르게 접근하여 주목을 받는 동안, 다른 기술자들에게 고차원적인 창조를 하도록 자극하면서 그들의 촉매제 역할을 하여 신뢰를 얻었다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "GbuQON2YmWpV",
    "outputId": "c5b95910-3476-46af-e09b-e9320b684c05"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic": {
       "type": "string"
      },
      "text/plain": [
       "'과기정통부, 22일 유영민 장관 등 참석해 기념행사2021년까지 1516억원 투입, 510'"
      ]
     },
     "execution_count": 198,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_news_by_url(url):\n",
    "  res = requests.get(url)\n",
    "  bs = BeautifulSoup(res.content, 'html.parser')\n",
    "\n",
    "  title = bs.select('h3#articleTitle')[0].text #제목\n",
    "  content = bs.select('#articleBodyContents')[0].get_text().replace('\\n', \" \") #본문\n",
    "  content = content.replace(\"// flash 오류를 우회하기 위한 함수 추가 function _flash_removeCallback() {}\", \"\")\n",
    "  return  content.strip()\n",
    "\n",
    "doc = get_news_by_url('https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=105&oid=018&aid=0004430108')\n",
    "doc[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "7IIA2vf5kbq9",
    "outputId": "8fe9688f-d474-4f05-ed86-9d6bcaf26b37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 199,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UPM0f2uh5eq0"
   },
   "source": [
    "### 1) 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "colab_type": "code",
    "id": "wx-BvGWVpmc7",
    "outputId": "f7a50439-e950-43cb-da99-1b9ae2b57042"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic": {
       "type": "string"
      },
      "text/plain": [
       "'과기정통부, 22일 유영민 장관 등 참석해 기념행사2021년까지 1516억원 투입, 5100여종 데이터 구축민간 클라우드 통한 외부연계체계도..\"개방성 강화\"[이데일리 이재운 기자] 국가 차원의 빅데이터 활용 시대가 열린다. 새로운 산업 창출과 기존 산업의 변화에 이르는 ‘혁신성장’을 위한 센터가 문을 연다. 10개 분야에 걸쳐 ‘데이터 경제’의 발전을 위한 정부의 청사진을 현실로 구현하는데 앞장선다는 계획이다.22일 과학기술정보통신부는 서울 중구 대한상공회의소에서 데이터 생태계 조성과 혁신 성장의 기반 마련을 위한 ‘빅데이터 플랫폼 및 센터’ 출범식 행사를 개최했다. 유영민 과기정통부 장관을 비롯해 노웅래 국회 과학기술정보방송통신위원회 위원장 등 300여명이 참가했다.◇10개 분야 100개 센터..3년간 1516억원 투입이미지: 픽사베이빅데이터는 데이터 활용을 통해 혁신성장을 이루자는 문재인 정부의 경제 성장 핵심 요소중 하나다. 문재인 대통령이 직접 올 들어 데이터 활용과 이에 따른 정보보호(보안)에 대한 중요성을 강조하기도 했다.이런 맥락 속에서 빅데이터센터는 공공과 민간이 협업해 활용도 높은 양질의 데이터를 생산·구축하고, 플랫폼은 이를 수집·분석·유통하는 역할을 담당한다. 과기정통부는 분야별 플랫폼 10개소와 이와 연계된 기관별 센터 100개소를 구축하는데 3년간 총 1516억원을 투입할 계획이며, 올해 우선 640억원 규모의 사업을 추진하고 있다.대상 분야는 △금융(BC카드) △환경(한국수자원공사) △문화(한국문화정보원) △교통(한국교통연구원) △헬스케어(국립암센터) △유통·소비(매일방송) △통신(KT) △중소기업(더존비즈온) △지역경제(경기도청) △산림(한국임업진흥원) 등으로 현재 1차 공모를 통해 72개 빅데이터 센터를 선정했고, 다음달 8일까지 2차 공모를 통해 28개를 추가 선정해 총 100개를 지원, 운영할 계획이다. 이를 통해 데이터 생태계를 혁신하고 기업의 경쟁력을 제고하는 역할을 수행한다.주요 활용 전략·사례를 보면 빅데이터 활용을 통해 ‘신(新) 시장’을 창출하는 방안을 담고 있다. 금융 플랫폼의 경우 소상공인 신용평가 고도화 등을 통해 금융 취약 계층 대상 중금리 대출이자를 2%p 절감해 연간 1조원의 신규대출을 창출할 전망이다. 유통·소비와 중소기업 플랫폼은 소상공인이나 중소기업의 폐업률 감소를, 문화 플랫폼은 문화·예술 관람률과 생활체육 참여율을 높이는 방안을 모색한다. 의료비 절감(헬스케어)과 기업의 매출 향상을 통한 산업 육성(통신·산림) 등도 눈길을 끈다.과기정통부 제공◇2021년까지 5100여종 데이터 구축..AI 알고리즘 제공도센터는 우선 분야별 데이터 부족 문제를 해소하기 위해 올해 말까지 시장 수요가 높은 1400여종 신규 데이터를 생산ㆍ구축하고, 사업이 완료되는 2021년까지 총 5100여종 양질의 풍부한 데이터를 생산·구축해 시장에 공급할 계획이다.특히 공공과 민간 사이 데이터 파일형식 등이 달라 호환이 제대로 이뤄지지 못한 문제를 해소하기 위해 개방형 표준을 적용하고, 품질관리기준도 마련해 운영한다.기업들이 실제 활용 가능한 최신 데이터를 확보하는데도 수개월이 소요된다는 문제점을 개선하기 위한 방안도 추진한다. 센터와 플랫폼 간 연계체계에는 민간 클라우드를 기반으로 활용하고, 센터에 축적된 데이터도 계속 외부와 개방·공유하며 최신·연속성을 확보한다는 계획이다.100개 센터에서 수집된 데이터를 융합·분석한 뒤 맞춤형 데이터 제작 등 양질의 데이터로 재생산하고, 기업들이 필요로 하는 데이터를 원하는 형태로 즉시 활용할 수 있도록 제공할 계획이다. 다양한 분석 도구는 물론 인공지능(AI) 학습 알고리즘도 제공해 이용자가 보다 사용하기 편리한 환경을 제공한다.이밖에 필요한 데이터를 쉽게 등록하고 검색할 수 있도록 기준을 마련하고, 데이터 보유와 관리에 대한 체계(거버넌스)를 논의하는 ‘데이터 얼라이언스’를 구성해 보다 안전하게 이용하는 방안도 마련했다.유영민 과기정통부 장관은 “오늘 출범식은 대한민국이 데이터 강국으로 가기 위한 초석을 놓은 자리”라며 “세계 주요국들보다 데이터 경제로 나아가는 발걸음이 다소 늦었지만, 빅데이터 플랫폼과 센터를 지렛대로 우리나라의 낙후된 데이터 생태계를 혁신하고 기업의 경쟁력을 한 단계 제고할 수 있도록 정책적 역량을 집중하겠다”고 밝혔다.이재운 (jwlee@edaily.co.kr)네이버 홈에서 ‘이데일리’ 뉴스 [구독하기▶]꿀잼가득 [영상보기▶] , 청춘뉘우스~ [스냅타임▶]＜ⓒ종합 경제정보 미디어 이데일리 - 무단전재 & 재배포 금지＞'"
      ]
     },
     "execution_count": 200,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ZceMBZBZlMM4",
    "outputId": "052fed28-cd48-4463-bacc-5f131663d551"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 176,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_token = sent_tokenize(doc)\n",
    "len(sent_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 613
    },
    "colab_type": "code",
    "id": "3ARlOKLtREmC",
    "outputId": "5edd1d94-1b70-48ae-82f9-70c7000dca13"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['과기정통부, 22일 유영민 장관 등 참석해 기념행사2021년까지 1516억원 투입, 5100여종 데이터 구축민간 클라우드 통한 외부연계체계도',\n",
       " '',\n",
       " '\"개방성 강화\"[이데일리 이재운 기자] 국가 차원의 빅데이터 활용 시대가 열린다',\n",
       " ' 새로운 산업 창출과 기존 산업의 변화에 이르는 ‘혁신성장’을 위한 센터가 문을 연다',\n",
       " ' 10개 분야에 걸쳐 ‘데이터 경제’의 발전을 위한 정부의 청사진을 현실로 구현하는데 앞장선다는 계획이다',\n",
       " '22일 과학기술정보통신부는 서울 중구 대한상공회의소에서 데이터 생태계 조성과 혁신 성장의 기반 마련을 위한 ‘빅데이터 플랫폼 및 센터’ 출범식 행사를 개최했다',\n",
       " ' 유영민 과기정통부 장관을 비롯해 노웅래 국회 과학기술정보방송통신위원회 위원장 등 300여명이 참가했다',\n",
       " '◇10개 분야 100개 센터',\n",
       " '',\n",
       " '3년간 1516억원 투입이미지: 픽사베이빅데이터는 데이터 활용을 통해 혁신성장을 이루자는 문재인 정부의 경제 성장 핵심 요소중 하나다',\n",
       " ' 문재인 대통령이 직접 올 들어 데이터 활용과 이에 따른 정보보호(보안)에 대한 중요성을 강조하기도 했다',\n",
       " '이런 맥락 속에서 빅데이터센터는 공공과 민간이 협업해 활용도 높은 양질의 데이터를 생산·구축하고, 플랫폼은 이를 수집·분석·유통하는 역할을 담당한다',\n",
       " ' 과기정통부는 분야별 플랫폼 10개소와 이와 연계된 기관별 센터 100개소를 구축하는데 3년간 총 1516억원을 투입할 계획이며, 올해 우선 640억원 규모의 사업을 추진하고 있다',\n",
       " '대상 분야는 △금융(BC카드) △환경(한국수자원공사) △문화(한국문화정보원) △교통(한국교통연구원) △헬스케어(국립암센터) △유통·소비(매일방송) △통신(KT) △중소기업(더존비즈온) △지역경제(경기도청) △산림(한국임업진흥원) 등으로 현재 1차 공모를 통해 72개 빅데이터 센터를 선정했고, 다음달 8일까지 2차 공모를 통해 28개를 추가 선정해 총 100개를 지원, 운영할 계획이다',\n",
       " ' 이를 통해 데이터 생태계를 혁신하고 기업의 경쟁력을 제고하는 역할을 수행한다',\n",
       " '주요 활용 전략·사례를 보면 빅데이터 활용을 통해 ‘신(新) 시장’을 창출하는 방안을 담고 있다',\n",
       " ' 금융 플랫폼의 경우 소상공인 신용평가 고도화 등을 통해 금융 취약 계층 대상 중금리 대출이자를 2%p 절감해 연간 1조원의 신규대출을 창출할 전망이다',\n",
       " ' 유통·소비와 중소기업 플랫폼은 소상공인이나 중소기업의 폐업률 감소를, 문화 플랫폼은 문화·예술 관람률과 생활체육 참여율을 높이는 방안을 모색한다',\n",
       " ' 의료비 절감(헬스케어)과 기업의 매출 향상을 통한 산업 육성(통신·산림) 등도 눈길을 끈다',\n",
       " '과기정통부 제공◇2021년까지 5100여종 데이터 구축',\n",
       " '',\n",
       " 'AI 알고리즘 제공도센터는 우선 분야별 데이터 부족 문제를 해소하기 위해 올해 말까지 시장 수요가 높은 1400여종 신규 데이터를 생산ㆍ구축하고, 사업이 완료되는 2021년까지 총 5100여종 양질의 풍부한 데이터를 생산·구축해 시장에 공급할 계획이다',\n",
       " '특히 공공과 민간 사이 데이터 파일형식 등이 달라 호환이 제대로 이뤄지지 못한 문제를 해소하기 위해 개방형 표준을 적용하고, 품질관리기준도 마련해 운영한다',\n",
       " '기업들이 실제 활용 가능한 최신 데이터를 확보하는데도 수개월이 소요된다는 문제점을 개선하기 위한 방안도 추진한다',\n",
       " ' 센터와 플랫폼 간 연계체계에는 민간 클라우드를 기반으로 활용하고, 센터에 축적된 데이터도 계속 외부와 개방·공유하며 최신·연속성을 확보한다는 계획이다',\n",
       " '100개 센터에서 수집된 데이터를 융합·분석한 뒤 맞춤형 데이터 제작 등 양질의 데이터로 재생산하고, 기업들이 필요로 하는 데이터를 원하는 형태로 즉시 활용할 수 있도록 제공할 계획이다',\n",
       " ' 다양한 분석 도구는 물론 인공지능(AI) 학습 알고리즘도 제공해 이용자가 보다 사용하기 편리한 환경을 제공한다',\n",
       " '이밖에 필요한 데이터를 쉽게 등록하고 검색할 수 있도록 기준을 마련하고, 데이터 보유와 관리에 대한 체계(거버넌스)를 논의하는 ‘데이터 얼라이언스’를 구성해 보다 안전하게 이용하는 방안도 마련했다',\n",
       " '유영민 과기정통부 장관은 “오늘 출범식은 대한민국이 데이터 강국으로 가기 위한 초석을 놓은 자리”라며 “세계 주요국들보다 데이터 경제로 나아가는 발걸음이 다소 늦었지만, 빅데이터 플랫폼과 센터를 지렛대로 우리나라의 낙후된 데이터 생태계를 혁신하고 기업의 경쟁력을 한 단계 제고할 수 있도록 정책적 역량을 집중하겠다”고 밝혔다',\n",
       " '이재운 (jwlee@edaily',\n",
       " 'co',\n",
       " 'kr)네이버 홈에서 ‘이데일리’ 뉴스 [구독하기▶]꿀잼가득 [영상보기▶] , 청춘뉘우스~ [스냅타임▶]＜ⓒ종합 경제정보 미디어 이데일리 - 무단전재 & 재배포 금지＞']"
      ]
     },
     "execution_count": 177,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xRDgb1Ksd3VH"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "# 문장 분리\n",
    "def get_sentences(txt):\n",
    "  sentences =  sent_tokenize(txt)\n",
    "  return sentences\n",
    "\n",
    "# 토큰화 \n",
    "def get_words(txt):\n",
    "  mecab = Mecab()\n",
    "  tokens = []\n",
    "\n",
    "  tokens = [token for token in mecab.pos(txt)]\n",
    "  \n",
    "  return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 557
    },
    "colab_type": "code",
    "id": "q3zERtBgnHIH",
    "outputId": "86d33097-5aba-40a7-88bc-88afc79a6c47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('과기', 'NNG'),\n",
       " ('정통부', 'NNG'),\n",
       " (',', 'SC'),\n",
       " ('22', 'SN'),\n",
       " ('일', 'NNBC'),\n",
       " ('유영민', 'NNP'),\n",
       " ('장관', 'NNG'),\n",
       " ('등', 'NNB'),\n",
       " ('참석', 'NNG'),\n",
       " ('해', 'XSV+EC'),\n",
       " ('기념행사', 'NNG'),\n",
       " ('2021', 'SN'),\n",
       " ('년', 'NNBC'),\n",
       " ('까지', 'JX'),\n",
       " ('1516', 'SN'),\n",
       " ('억', 'NR'),\n",
       " ('원', 'NNBC'),\n",
       " ('투입', 'NNG'),\n",
       " (',', 'SC'),\n",
       " ('5100', 'SN'),\n",
       " ('여종', 'NNG'),\n",
       " ('데이터', 'NNG'),\n",
       " ('구축', 'NNG'),\n",
       " ('민간', 'NNG'),\n",
       " ('클라우드', 'NNP'),\n",
       " ('통한', 'VV+ETM'),\n",
       " ('외부', 'NNG'),\n",
       " ('연계', 'NNG'),\n",
       " ('체계', 'NNG'),\n",
       " ('도', 'JX')]"
      ]
     },
     "execution_count": 201,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = get_words(doc)\n",
    "tokens[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lsVUL-Bg5sIw"
   },
   "source": [
    "### 2) 중요 단어 결정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "UXqJIxS1oNMZ",
    "outputId": "a481a31d-5268-4ded-cf19-229be15517d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['장관', '소비', '운영', '강화', '소요', '기술', '픽사', '년', '소상', '세계']"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocabs = []\n",
    "# for i in range(len(tokens)):\n",
    "#   vocabs.extend(tokens[i])\n",
    "# vocabs = list(set(vocabs))\n",
    "# vocabs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w6X3Kwj_oIRh"
   },
   "outputs": [],
   "source": [
    "# 단어(토큰)의 가중치 계산 및 범위에 포함되는 토큰 식별 \n",
    "def get_keywords(word_list , min_ratio=0.001, max_ratio=0.5) :\n",
    "  vocabs = [token[0] for token in tokens if token[1][0] ==\"N\"]\n",
    "  \n",
    "  keywords = []\n",
    "  for word in vocabs:\n",
    "    count = 0\n",
    "    for token in word_list:\n",
    "      if word == token[0]:\n",
    "        count += 1\n",
    "\n",
    "    weight = count / len(tokens)\n",
    "    if weight >= min_ratio and weight <= max_ratio:\n",
    "      keywords.append(word)\n",
    "  \n",
    "  return keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "QH5eT0zYGoc3",
    "outputId": "6c0a4b24-b073-4731-a79f-d033d0b89657"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1085, 331)"
      ]
     },
     "execution_count": 203,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords =get_keywords(tokens)\n",
    "\n",
    "len(tokens), len(keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NmEk0zbd5vcx"
   },
   "source": [
    "### 3) 문장 중요도 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "colab_type": "code",
    "id": "uKE8MwJ-KeCD",
    "outputId": "6fe360ab-0db9-4063-c684-23f9a947c69d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['과기정통부, 22일 유영민 장관 등 참석해 기념행사2021년까지 1516억원 투입, 5100여종 데이터 구축민간 클라우드 통한 외부연계체계도..\"개방성 강화\"[이데일리 이재운 기자] 국가 차원의 빅데이터 활용 시대가 열린다.',\n",
       " '새로운 산업 창출과 기존 산업의 변화에 이르는 ‘혁신성장’을 위한 센터가 문을 연다.',\n",
       " '10개 분야에 걸쳐 ‘데이터 경제’의 발전을 위한 정부의 청사진을 현실로 구현하는데 앞장선다는 계획이다.22일 과학기술정보통신부는 서울 중구 대한상공회의소에서 데이터 생태계 조성과 혁신 성장의 기반 마련을 위한 ‘빅데이터 플랫폼 및 센터’ 출범식 행사를 개최했다.',\n",
       " '유영민 과기정통부 장관을 비롯해 노웅래 국회 과학기술정보방송통신위원회 위원장 등 300여명이 참가했다.◇10개 분야 100개 센터..3년간 1516억원 투입이미지: 픽사베이빅데이터는 데이터 활용을 통해 혁신성장을 이루자는 문재인 정부의 경제 성장 핵심 요소중 하나다.',\n",
       " '문재인 대통령이 직접 올 들어 데이터 활용과 이에 따른 정보보호(보안)에 대한 중요성을 강조하기도 했다.이런 맥락 속에서 빅데이터센터는 공공과 민간이 협업해 활용도 높은 양질의 데이터를 생산·구축하고, 플랫폼은 이를 수집·분석·유통하는 역할을 담당한다.',\n",
       " '과기정통부는 분야별 플랫폼 10개소와 이와 연계된 기관별 센터 100개소를 구축하는데 3년간 총 1516억원을 투입할 계획이며, 올해 우선 640억원 규모의 사업을 추진하고 있다.대상 분야는 △금융(BC카드) △환경(한국수자원공사) △문화(한국문화정보원) △교통(한국교통연구원) △헬스케어(국립암센터) △유통·소비(매일방송) △통신(KT) △중소기업(더존비즈온) △지역경제(경기도청) △산림(한국임업진흥원) 등으로 현재 1차 공모를 통해 72개 빅데이터 센터를 선정했고, 다음달 8일까지 2차 공모를 통해 28개를 추가 선정해 총 100개를 지원, 운영할 계획이다.',\n",
       " '이를 통해 데이터 생태계를 혁신하고 기업의 경쟁력을 제고하는 역할을 수행한다.주요 활용 전략·사례를 보면 빅데이터 활용을 통해 ‘신(新) 시장’을 창출하는 방안을 담고 있다.',\n",
       " '금융 플랫폼의 경우 소상공인 신용평가 고도화 등을 통해 금융 취약 계층 대상 중금리 대출이자를 2%p 절감해 연간 1조원의 신규대출을 창출할 전망이다.',\n",
       " '유통·소비와 중소기업 플랫폼은 소상공인이나 중소기업의 폐업률 감소를, 문화 플랫폼은 문화·예술 관람률과 생활체육 참여율을 높이는 방안을 모색한다.',\n",
       " '의료비 절감(헬스케어)과 기업의 매출 향상을 통한 산업 육성(통신·산림) 등도 눈길을 끈다.과기정통부 제공◇2021년까지 5100여종 데이터 구축..AI 알고리즘 제공도센터는 우선 분야별 데이터 부족 문제를 해소하기 위해 올해 말까지 시장 수요가 높은 1400여종 신규 데이터를 생산ㆍ구축하고, 사업이 완료되는 2021년까지 총 5100여종 양질의 풍부한 데이터를 생산·구축해 시장에 공급할 계획이다.특히 공공과 민간 사이 데이터 파일형식 등이 달라 호환이 제대로 이뤄지지 못한 문제를 해소하기 위해 개방형 표준을 적용하고, 품질관리기준도 마련해 운영한다.기업들이 실제 활용 가능한 최신 데이터를 확보하는데도 수개월이 소요된다는 문제점을 개선하기 위한 방안도 추진한다.',\n",
       " '센터와 플랫폼 간 연계체계에는 민간 클라우드를 기반으로 활용하고, 센터에 축적된 데이터도 계속 외부와 개방·공유하며 최신·연속성을 확보한다는 계획이다.100개 센터에서 수집된 데이터를 융합·분석한 뒤 맞춤형 데이터 제작 등 양질의 데이터로 재생산하고, 기업들이 필요로 하는 데이터를 원하는 형태로 즉시 활용할 수 있도록 제공할 계획이다.',\n",
       " '다양한 분석 도구는 물론 인공지능(AI) 학습 알고리즘도 제공해 이용자가 보다 사용하기 편리한 환경을 제공한다.이밖에 필요한 데이터를 쉽게 등록하고 검색할 수 있도록 기준을 마련하고, 데이터 보유와 관리에 대한 체계(거버넌스)를 논의하는 ‘데이터 얼라이언스’를 구성해 보다 안전하게 이용하는 방안도 마련했다.유영민 과기정통부 장관은 “오늘 출범식은 대한민국이 데이터 강국으로 가기 위한 초석을 놓은 자리”라며 “세계 주요국들보다 데이터 경제로 나아가는 발걸음이 다소 늦었지만, 빅데이터 플랫폼과 센터를 지렛대로 우리나라의 낙후된 데이터 생태계를 혁신하고 기업의 경쟁력을 한 단계 제고할 수 있도록 정책적 역량을 집중하겠다”고 밝혔다.이재운 (jwlee@edaily.co.kr)네이버 홈에서 ‘이데일리’ 뉴스 [구독하기▶]꿀잼가득 [영상보기▶] , 청춘뉘우스~ [스냅타임▶]＜ⓒ종합 경제정보 미디어 이데일리 - 무단전재 & 재배포 금지＞']"
      ]
     },
     "execution_count": 145,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "colab_type": "code",
    "id": "baCiV7VYKfP9",
    "outputId": "e99bd514-ac27-44b3-fa58-5f78945852b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.297872340425531\n",
      "2.0\n",
      "10.245901639344263\n",
      "13.432835820895523\n",
      "8.347826086956522\n",
      "21.301775147928993\n",
      "5.565217391304348\n",
      "6.2439024390243905\n",
      "3.361111111111111\n",
      "21.888235294117646\n",
      "13.315217391304348\n",
      "10.766355140186915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10.766355140186915"
      ]
     },
     "execution_count": 153,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(sent_token)):\n",
    "  word_token = get_words(sent_token[i])\n",
    "  index = []\n",
    "\n",
    "  for j, token in enumerate(word_token):\n",
    "    if token[0] in keywords:\n",
    "      index.append(j)\n",
    "\n",
    "  window_size = max(index) - min(index) + 1\n",
    "  score = len(index)*len(index) / window_size\n",
    "  print(score)\n",
    "\n",
    "  index = []\n",
    "\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "AB8gb8BbaUT2",
    "outputId": "6de919dd-d209-4399-c6d0-7abceea0b391"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "index = []\n",
    "if not index:\n",
    "  print('a')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K-mVXXWYoK5C"
   },
   "outputs": [],
   "source": [
    "# 문장의 가중치 계산\n",
    "def get_sentence_weight (sentence , keywords):\n",
    "  word_token = get_words(sentence)\n",
    "  index = []\n",
    "\n",
    "  for j, token in enumerate(word_token):\n",
    "    if token[0] in keywords:\n",
    "      index.append(j)\n",
    "\n",
    "  if not index:\n",
    "    score=0\n",
    "    return score\n",
    "    \n",
    "  else:  \n",
    "    window_size = max(index) - min(index) + 1   \n",
    "    score = len(index)*len(index) / window_size\n",
    "  \n",
    "  return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "colab_type": "code",
    "id": "l8P21pKlOIPD",
    "outputId": "53934592-7862-4003-fd2e-478d6c90d814"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13.297872340425531,\n",
       " 2.0,\n",
       " 10.245901639344263,\n",
       " 13.432835820895523,\n",
       " 8.347826086956522,\n",
       " 21.301775147928993,\n",
       " 5.565217391304348,\n",
       " 6.2439024390243905,\n",
       " 3.361111111111111,\n",
       " 21.888235294117646,\n",
       " 13.315217391304348,\n",
       " 10.766355140186915]"
      ]
     },
     "execution_count": 234,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = []\n",
    "for sen in sent_token:\n",
    "  score.append(get_sentence_weight(sen, keywords))\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rufxIxIb5zq9"
   },
   "source": [
    "### 4) 문서 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "id": "NuSr4ynsPNNa",
    "outputId": "2943f33f-84b5-4acb-8891-a7bd4dd3f67d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['의료비 절감(헬스케어)과 기업의 매출 향상을 통한 산업 육성(통신·산림) 등도 눈길을 끈다.과기정통부 제공◇2021년까지 5100여종 데이터 구축..AI 알고리즘 제공도센터는 우선 분야별 데이터 부족 문제를 해소하기 위해 올해 말까지 시장 수요가 높은 1400여종 신규 데이터를 생산ㆍ구축하고, 사업이 완료되는 2021년까지 총 5100여종 양질의 풍부한 데이터를 생산·구축해 시장에 공급할 계획이다.특히 공공과 민간 사이 데이터 파일형식 등이 달라 호환이 제대로 이뤄지지 못한 문제를 해소하기 위해 개방형 표준을 적용하고, 품질관리기준도 마련해 운영한다.기업들이 실제 활용 가능한 최신 데이터를 확보하는데도 수개월이 소요된다는 문제점을 개선하기 위한 방안도 추진한다.',\n",
       " '과기정통부는 분야별 플랫폼 10개소와 이와 연계된 기관별 센터 100개소를 구축하는데 3년간 총 1516억원을 투입할 계획이며, 올해 우선 640억원 규모의 사업을 추진하고 있다.대상 분야는 △금융(BC카드) △환경(한국수자원공사) △문화(한국문화정보원) △교통(한국교통연구원) △헬스케어(국립암센터) △유통·소비(매일방송) △통신(KT) △중소기업(더존비즈온) △지역경제(경기도청) △산림(한국임업진흥원) 등으로 현재 1차 공모를 통해 72개 빅데이터 센터를 선정했고, 다음달 8일까지 2차 공모를 통해 28개를 추가 선정해 총 100개를 지원, 운영할 계획이다.',\n",
       " '유영민 과기정통부 장관을 비롯해 노웅래 국회 과학기술정보방송통신위원회 위원장 등 300여명이 참가했다.◇10개 분야 100개 센터..3년간 1516억원 투입이미지: 픽사베이빅데이터는 데이터 활용을 통해 혁신성장을 이루자는 문재인 정부의 경제 성장 핵심 요소중 하나다.',\n",
       " '센터와 플랫폼 간 연계체계에는 민간 클라우드를 기반으로 활용하고, 센터에 축적된 데이터도 계속 외부와 개방·공유하며 최신·연속성을 확보한다는 계획이다.100개 센터에서 수집된 데이터를 융합·분석한 뒤 맞춤형 데이터 제작 등 양질의 데이터로 재생산하고, 기업들이 필요로 하는 데이터를 원하는 형태로 즉시 활용할 수 있도록 제공할 계획이다.',\n",
       " '과기정통부, 22일 유영민 장관 등 참석해 기념행사2021년까지 1516억원 투입, 5100여종 데이터 구축민간 클라우드 통한 외부연계체계도..\"개방성 강화\"[이데일리 이재운 기자] 국가 차원의 빅데이터 활용 시대가 열린다.']"
      ]
     },
     "execution_count": 206,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "score = np.array(score)\n",
    "\n",
    "key_sen_index = score.argsort()[::-1]\n",
    "\n",
    "key_sen = []\n",
    "for index in key_sen_index[:5]:\n",
    "  key_sen.append(sent_token[index])\n",
    "key_sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "colab_type": "code",
    "id": "Lmcf22JhR0du",
    "outputId": "4f9fbb57-f096-43bc-c561-bc3ab4645155"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['과기정통부, 22일 유영민 장관 등 참석해 기념행사2021년까지 1516억원 투입, 5100여종 데이터 구축민간 클라우드 통한 외부연계체계도..\"개방성 강화\"[이데일리 이재운 기자] 국가 차원의 빅데이터 활용 시대가 열린다.',\n",
       " '새로운 산업 창출과 기존 산업의 변화에 이르는 ‘혁신성장’을 위한 센터가 문을 연다.',\n",
       " '10개 분야에 걸쳐 ‘데이터 경제’의 발전을 위한 정부의 청사진을 현실로 구현하는데 앞장선다는 계획이다.22일 과학기술정보통신부는 서울 중구 대한상공회의소에서 데이터 생태계 조성과 혁신 성장의 기반 마련을 위한 ‘빅데이터 플랫폼 및 센터’ 출범식 행사를 개최했다.',\n",
       " '유영민 과기정통부 장관을 비롯해 노웅래 국회 과학기술정보방송통신위원회 위원장 등 300여명이 참가했다.◇10개 분야 100개 센터..3년간 1516억원 투입이미지: 픽사베이빅데이터는 데이터 활용을 통해 혁신성장을 이루자는 문재인 정부의 경제 성장 핵심 요소중 하나다.',\n",
       " '문재인 대통령이 직접 올 들어 데이터 활용과 이에 따른 정보보호(보안)에 대한 중요성을 강조하기도 했다.이런 맥락 속에서 빅데이터센터는 공공과 민간이 협업해 활용도 높은 양질의 데이터를 생산·구축하고, 플랫폼은 이를 수집·분석·유통하는 역할을 담당한다.',\n",
       " '과기정통부는 분야별 플랫폼 10개소와 이와 연계된 기관별 센터 100개소를 구축하는데 3년간 총 1516억원을 투입할 계획이며, 올해 우선 640억원 규모의 사업을 추진하고 있다.대상 분야는 △금융(BC카드) △환경(한국수자원공사) △문화(한국문화정보원) △교통(한국교통연구원) △헬스케어(국립암센터) △유통·소비(매일방송) △통신(KT) △중소기업(더존비즈온) △지역경제(경기도청) △산림(한국임업진흥원) 등으로 현재 1차 공모를 통해 72개 빅데이터 센터를 선정했고, 다음달 8일까지 2차 공모를 통해 28개를 추가 선정해 총 100개를 지원, 운영할 계획이다.',\n",
       " '이를 통해 데이터 생태계를 혁신하고 기업의 경쟁력을 제고하는 역할을 수행한다.주요 활용 전략·사례를 보면 빅데이터 활용을 통해 ‘신(新) 시장’을 창출하는 방안을 담고 있다.',\n",
       " '금융 플랫폼의 경우 소상공인 신용평가 고도화 등을 통해 금융 취약 계층 대상 중금리 대출이자를 2%p 절감해 연간 1조원의 신규대출을 창출할 전망이다.',\n",
       " '유통·소비와 중소기업 플랫폼은 소상공인이나 중소기업의 폐업률 감소를, 문화 플랫폼은 문화·예술 관람률과 생활체육 참여율을 높이는 방안을 모색한다.',\n",
       " '의료비 절감(헬스케어)과 기업의 매출 향상을 통한 산업 육성(통신·산림) 등도 눈길을 끈다.과기정통부 제공◇2021년까지 5100여종 데이터 구축..AI 알고리즘 제공도센터는 우선 분야별 데이터 부족 문제를 해소하기 위해 올해 말까지 시장 수요가 높은 1400여종 신규 데이터를 생산ㆍ구축하고, 사업이 완료되는 2021년까지 총 5100여종 양질의 풍부한 데이터를 생산·구축해 시장에 공급할 계획이다.특히 공공과 민간 사이 데이터 파일형식 등이 달라 호환이 제대로 이뤄지지 못한 문제를 해소하기 위해 개방형 표준을 적용하고, 품질관리기준도 마련해 운영한다.기업들이 실제 활용 가능한 최신 데이터를 확보하는데도 수개월이 소요된다는 문제점을 개선하기 위한 방안도 추진한다.',\n",
       " '센터와 플랫폼 간 연계체계에는 민간 클라우드를 기반으로 활용하고, 센터에 축적된 데이터도 계속 외부와 개방·공유하며 최신·연속성을 확보한다는 계획이다.100개 센터에서 수집된 데이터를 융합·분석한 뒤 맞춤형 데이터 제작 등 양질의 데이터로 재생산하고, 기업들이 필요로 하는 데이터를 원하는 형태로 즉시 활용할 수 있도록 제공할 계획이다.',\n",
       " '다양한 분석 도구는 물론 인공지능(AI) 학습 알고리즘도 제공해 이용자가 보다 사용하기 편리한 환경을 제공한다.이밖에 필요한 데이터를 쉽게 등록하고 검색할 수 있도록 기준을 마련하고, 데이터 보유와 관리에 대한 체계(거버넌스)를 논의하는 ‘데이터 얼라이언스’를 구성해 보다 안전하게 이용하는 방안도 마련했다.유영민 과기정통부 장관은 “오늘 출범식은 대한민국이 데이터 강국으로 가기 위한 초석을 놓은 자리”라며 “세계 주요국들보다 데이터 경제로 나아가는 발걸음이 다소 늦었지만, 빅데이터 플랫폼과 센터를 지렛대로 우리나라의 낙후된 데이터 생태계를 혁신하고 기업의 경쟁력을 한 단계 제고할 수 있도록 정책적 역량을 집중하겠다”고 밝혔다.이재운 (jwlee@edaily.co.kr)네이버 홈에서 ‘이데일리’ 뉴스 [구독하기▶]꿀잼가득 [영상보기▶] , 청춘뉘우스~ [스냅타임▶]＜ⓒ종합 경제정보 미디어 이데일리 - 무단전재 & 재배포 금지＞']"
      ]
     },
     "execution_count": 207,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentences(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZntB_Sx0d832"
   },
   "outputs": [],
   "source": [
    "# 문서 요약\n",
    "import numpy as np\n",
    "\n",
    "def summarize(content ,max_no_of_sentences = 10):\n",
    "  sent_token = get_sentences(content)\n",
    "  tokens = get_words(content)\n",
    "  keywords =get_keywords(tokens)\n",
    "  score = []\n",
    "  for sen in sent_token:\n",
    "    score.append(get_sentence_weight(sen, keywords))\n",
    "  score = np.array(score)\n",
    "\n",
    "  key_sen_index = score.argsort()[::-1]\n",
    "  key_sen = []\n",
    "  for index in key_sen_index[:max_no_of_sentences]:\n",
    "    key_sen.append(sent_token[index])\n",
    "\n",
    "  return key_sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 935
    },
    "colab_type": "code",
    "id": "yhnXHED_SU3J",
    "outputId": "8ac2fed6-265d-406b-c85c-d21a4d87421a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('과기', 'NNG'),\n",
       " ('정통부', 'NNG'),\n",
       " (',', 'SC'),\n",
       " ('22', 'SN'),\n",
       " ('일', 'NNBC'),\n",
       " ('유영민', 'NNP'),\n",
       " ('장관', 'NNG'),\n",
       " ('등', 'NNB'),\n",
       " ('참석', 'NNG'),\n",
       " ('해', 'XSV+EC'),\n",
       " ('기념행사', 'NNG'),\n",
       " ('2021', 'SN'),\n",
       " ('년', 'NNBC'),\n",
       " ('까지', 'JX'),\n",
       " ('1516', 'SN'),\n",
       " ('억', 'NR'),\n",
       " ('원', 'NNBC'),\n",
       " ('투입', 'NNG'),\n",
       " (',', 'SC'),\n",
       " ('5100', 'SN'),\n",
       " ('여종', 'NNG'),\n",
       " ('데이터', 'NNG'),\n",
       " ('구축', 'NNG'),\n",
       " ('민간', 'NNG'),\n",
       " ('클라우드', 'NNP'),\n",
       " ('통한', 'VV+ETM'),\n",
       " ('외부', 'NNG'),\n",
       " ('연계', 'NNG'),\n",
       " ('체계', 'NNG'),\n",
       " ('도', 'JX'),\n",
       " ('.', 'SF'),\n",
       " ('.\"', 'SY'),\n",
       " ('개방', 'NNG'),\n",
       " ('성', 'XSN'),\n",
       " ('강화', 'NNG'),\n",
       " ('\"[', 'SY'),\n",
       " ('이', 'JKS'),\n",
       " ('데일리', 'NNP'),\n",
       " ('이재운', 'NNP'),\n",
       " ('기자', 'NNG'),\n",
       " (']', 'SSC'),\n",
       " ('국가', 'NNG'),\n",
       " ('차원', 'NNG'),\n",
       " ('의', 'JKG'),\n",
       " ('빅', 'NNG'),\n",
       " ('데이터', 'NNG'),\n",
       " ('활용', 'NNG'),\n",
       " ('시대', 'NNG'),\n",
       " ('가', 'JKS'),\n",
       " ('열린다', 'VV+EF'),\n",
       " ('.', 'SF')]"
      ]
     },
     "execution_count": 225,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_token = get_sentences(doc)\n",
    "get_words(sent_token[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "id": "mmZxMoce6S3E",
    "outputId": "7d3b8ad6-a7d2-42c0-a8e6-5c1eca28b7aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "의료비 절감(헬스케어)과 기업의 매출 향상을 통한 산업 육성(통신·산림) 등도 눈길을 끈다.과기정통부 제공◇2021년까지 5100여종 데이터 구축..AI 알고리즘 제공도센터는 우선 분야별 데이터 부족 문제를 해소하기 위해 올해 말까지 시장 수요가 높은 1400여종 신규 데이터를 생산ㆍ구축하고, 사업이 완료되는 2021년까지 총 5100여종 양질의 풍부한 데이터를 생산·구축해 시장에 공급할 계획이다.특히 공공과 민간 사이 데이터 파일형식 등이 달라 호환이 제대로 이뤄지지 못한 문제를 해소하기 위해 개방형 표준을 적용하고, 품질관리기준도 마련해 운영한다.기업들이 실제 활용 가능한 최신 데이터를 확보하는데도 수개월이 소요된다는 문제점을 개선하기 위한 방안도 추진한다.\n",
      "과기정통부는 분야별 플랫폼 10개소와 이와 연계된 기관별 센터 100개소를 구축하는데 3년간 총 1516억원을 투입할 계획이며, 올해 우선 640억원 규모의 사업을 추진하고 있다.대상 분야는 △금융(BC카드) △환경(한국수자원공사) △문화(한국문화정보원) △교통(한국교통연구원) △헬스케어(국립암센터) △유통·소비(매일방송) △통신(KT) △중소기업(더존비즈온) △지역경제(경기도청) △산림(한국임업진흥원) 등으로 현재 1차 공모를 통해 72개 빅데이터 센터를 선정했고, 다음달 8일까지 2차 공모를 통해 28개를 추가 선정해 총 100개를 지원, 운영할 계획이다.\n",
      "유영민 과기정통부 장관을 비롯해 노웅래 국회 과학기술정보방송통신위원회 위원장 등 300여명이 참가했다.◇10개 분야 100개 센터..3년간 1516억원 투입이미지: 픽사베이빅데이터는 데이터 활용을 통해 혁신성장을 이루자는 문재인 정부의 경제 성장 핵심 요소중 하나다.\n",
      "센터와 플랫폼 간 연계체계에는 민간 클라우드를 기반으로 활용하고, 센터에 축적된 데이터도 계속 외부와 개방·공유하며 최신·연속성을 확보한다는 계획이다.100개 센터에서 수집된 데이터를 융합·분석한 뒤 맞춤형 데이터 제작 등 양질의 데이터로 재생산하고, 기업들이 필요로 하는 데이터를 원하는 형태로 즉시 활용할 수 있도록 제공할 계획이다.\n",
      "과기정통부, 22일 유영민 장관 등 참석해 기념행사2021년까지 1516억원 투입, 5100여종 데이터 구축민간 클라우드 통한 외부연계체계도..\"개방성 강화\"[이데일리 이재운 기자] 국가 차원의 빅데이터 활용 시대가 열린다.\n"
     ]
    }
   ],
   "source": [
    "li = summarize (doc ,  5)\n",
    "for s in li :\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ctQ8vU85d2Uy"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "79hL5vXiUyZZ"
   },
   "source": [
    "## 쌤 ver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6AKnL-9BU2NN"
   },
   "source": [
    "1) 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e2JS-3eYU6Xz"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "# 문장 분리\n",
    "def get_sentences(txt):\n",
    "  return sent_tokenize(txt)\n",
    "\n",
    "# 토큰화 \n",
    "def get_words(txt):\n",
    "  mecab = Mecab()\n",
    "  return [t[0] for t in mecab.pos(txt) if t[0] not in stopwords and t[1][0] == 'N']\n",
    "\n",
    "  # if t[0] not in stopwords and t[1][0] == 'N' 이걸 추가해주면 좀더 퀄리티가 좋아짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "26ebdJbWUz6b"
   },
   "source": [
    "2) 중요 단어 결정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "eCCC_nSZVZ3z",
    "outputId": "541d239b-ad57-442a-f2a5-4ea39471309a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'사과', '포도'}"
      ]
     },
     "execution_count": 256,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어(토큰)의 가중치 계산 및 범위에 포함되는 토큰 식별 \n",
    "def get_keywords(word_list , min_ratio=0.001, max_ratio=0.5) :\n",
    "    count_dict = {}\n",
    "    for word in word_list:\n",
    "      count_dict.setdefault(word, 0)\n",
    "      count_dict[word] += 1\n",
    "\n",
    "    keywords = set()\n",
    "    for word, cnt in count_dict.items():\n",
    "      word_percentage = count_dict[word] / len(word_list)\n",
    "\n",
    "      if word_percentage  <= max_ratio and word_percentage >= min_ratio:\n",
    "        keywords.add(word)\n",
    "\n",
    "    return keywords\n",
    "\n",
    "get_keywords(['바나나','사과','바나나','바나나','포도'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jOQH8G7pVT0T"
   },
   "source": [
    "3) 문장 중요도 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VwBF_Lu4WdSc"
   },
   "outputs": [],
   "source": [
    "# 문장의 가중치 계산\n",
    "def get_sentence_weight (sentence , keywords):\n",
    "    token_list = sentence.split(' ')\n",
    "    window_start = 0\n",
    "    window_end = -1\n",
    "\n",
    "    for i in range(len(token_list)):\n",
    "      if token_list[i] in keywords:\n",
    "        window_start = i\n",
    "        break\n",
    "    \n",
    "    for i in range(len(token_list) - 1, 0, -1):\n",
    "      if token_list[i] in keywords:\n",
    "        window_end = i\n",
    "        break\n",
    "      \n",
    "\n",
    "    if window_start > window_end:\n",
    "      return 0\n",
    "\n",
    "    window_size = window_end - window_start + 1\n",
    "\n",
    "    keywords_cnt = 0\n",
    "    for w in token_list:\n",
    "      if w in keywords:\n",
    "        keywords_cnt += 1\n",
    "\n",
    "    return keywords_cnt * keywords_cnt / window_size\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZXoosT9YXE4z"
   },
   "source": [
    "4) 문서요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9oP84il_XGUD"
   },
   "outputs": [],
   "source": [
    "# 문서 요약\n",
    "def summarize(content ,max_no_of_sentences = 10):\n",
    "    word_list = get_words(content)\n",
    "    \n",
    "    keywords = get_keywords(word_list, 0.001, 0.5)\n",
    "    \n",
    "    sentence_list = get_sentences(content)\n",
    "    sentence_score = []\n",
    "\n",
    "    for sentence in sentence_list:\n",
    "      sentence_score.append((get_sentence_weight(sentence, keywords), sentence))\n",
    "\n",
    "    sentence_score.sort(reverse = True)\n",
    "\n",
    "    ret_list = []\n",
    "    ret_cnt = min(max_no_of_sentences, len(sentence_list))\n",
    "    for i in range(ret_cnt):\n",
    "      ret_list.append( f\"{sentence_score[i][0]} : {sentence_score[i][1]}\" )\n",
    "\n",
    "    return ret_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "colab_type": "code",
    "id": "Kp1b3jj1XIuD",
    "outputId": "c42d6110-d81e-45a0-99f0-4ff8d6ab98d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.070422535211268 : 의료비 절감(헬스케어)과 기업의 매출 향상을 통한 산업 육성(통신·산림) 등도 눈길을 끈다.과기정통부 제공◇2021년까지 5100여종 데이터 구축..AI 알고리즘 제공도센터는 우선 분야별 데이터 부족 문제를 해소하기 위해 올해 말까지 시장 수요가 높은 1400여종 신규 데이터를 생산ㆍ구축하고, 사업이 완료되는 2021년까지 총 5100여종 양질의 풍부한 데이터를 생산·구축해 시장에 공급할 계획이다.특히 공공과 민간 사이 데이터 파일형식 등이 달라 호환이 제대로 이뤄지지 못한 문제를 해소하기 위해 개방형 표준을 적용하고, 품질관리기준도 마련해 운영한다.기업들이 실제 활용 가능한 최신 데이터를 확보하는데도 수개월이 소요된다는 문제점을 개선하기 위한 방안도 추진한다.\n",
      "3.2 : 과기정통부, 22일 유영민 장관 등 참석해 기념행사2021년까지 1516억원 투입, 5100여종 데이터 구축민간 클라우드 통한 외부연계체계도..\"개방성 강화\"[이데일리 이재운 기자] 국가 차원의 빅데이터 활용 시대가 열린다.\n",
      "2.0416666666666665 : 10개 분야에 걸쳐 ‘데이터 경제’의 발전을 위한 정부의 청사진을 현실로 구현하는데 앞장선다는 계획이다.22일 과학기술정보통신부는 서울 중구 대한상공회의소에서 데이터 생태계 조성과 혁신 성장의 기반 마련을 위한 ‘빅데이터 플랫폼 및 센터’ 출범식 행사를 개최했다.\n"
     ]
    }
   ],
   "source": [
    "li = summarize (doc ,  3)\n",
    "for s in li :\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xUOOmfhngBnb"
   },
   "source": [
    "# 9-2 Textrank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D2cG-zDxW0aW"
   },
   "source": [
    "![대체 텍스트](https://www.researchgate.net/profile/Khushboo_Thakkar3/publication/232645575/figure/fig1/AS:575720050573312@1514273764062/Sample-graph-build-for-sentence-extraction.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R-wrC-1D_a0V"
   },
   "source": [
    "## 2.1 TextRank 직접 구현하기 (Matrix 활용)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1LJjhauc6Jlz"
   },
   "source": [
    "### 1) 자카드 유사도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yu3gn_zOE-fv"
   },
   "outputs": [],
   "source": [
    "Text = \"딸기 바나나 사과 파인애플 수박. 바나나 사과 딸기 포도. 복숭아 수박. 파인애플 사과 딸기 바나나\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "PY0pac5zrwrb",
    "outputId": "e8f1f039-5dda-42e2-ba97-48bbbdcfaa5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['딸기 바나나 사과 파인애플 수박.', '바나나 사과 딸기 포도.', '복숭아 수박.', '파인애플 사과 딸기 바나나']"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "\n",
    "sentences = sent_tokenize(Text)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ev4s4s0YBxa3",
    "outputId": "3ceb4831-25f9-42bf-b7b9-9ed68c6e7671"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from konlpy.tag import Mecab\n",
    "\n",
    "# 문장간 유사도 측정 (자카드 유사도 사용)\n",
    "def sentence_similarity(sentence1, sentence2):\n",
    "  sent1_token = set(sentence1.split(\" \"))\n",
    "  sent2_token = set(sentence2.split(\" \"))\n",
    "\n",
    "  intersection = sent1_token & sent2_token\n",
    "  union = sent1_token | sent2_token\n",
    "\n",
    "  similarity = len(intersection) / len(union)\n",
    "  return similarity\n",
    "\n",
    "sentence_similarity('나는 치킨을 좋아해','나는 치킨을 싫어해')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "RaydDjkQ01rw",
    "outputId": "a70386e4-3980-498a-ab40-705e95812f42"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['딸기 바나나 사과 파인애플 수박.', '바나나 사과 딸기 포도.', '복숭아 수박.', '파인애플 사과 딸기 바나나']"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LK40WKvuvcE9",
    "outputId": "e0494425-a1ce-4bfb-a601-504bc3921e5e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_similarity(sentences[0], sentences[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8ma25LRfEx67"
   },
   "source": [
    "### 2) 그래프 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "52trbCb-tzs-",
    "outputId": "07855ba2-22e5-450e-84ce-af2dfe7b8ce3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.45454545, 1.        , 0.57142857],\n",
       "       [0.34090909, 0.        , 0.        , 0.42857143],\n",
       "       [0.11363636, 0.        , 0.        , 0.        ],\n",
       "       [0.54545455, 0.54545455, 0.        , 0.        ]])"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "sen_len = len(sentences)\n",
    "\n",
    "weighted_edge = np.zeros((sen_len, sen_len))\n",
    "\n",
    "sen_weight = []\n",
    "for i in range(sen_len):\n",
    "  sum_i = 0\n",
    "  for j in range(sen_len):\n",
    "     if i != j:\n",
    "      sum_i += sentence_similarity(sentences[i], sentences[j])\n",
    "      weighted_edge[j][i] = sentence_similarity(sentences[i], sentences[j]) \n",
    "  sen_weight.append(sum_i)\n",
    "  weighted_edge[:,i] = weighted_edge[:,i] / sum_i\n",
    "\n",
    "weighted_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ymW8HbnU6K94",
    "outputId": "0b3905d0-3db8-4cfa-c52f-e3d9c9ccefb8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.4666666666666668, 1.1, 0.16666666666666666, 1.4]"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "38ThXVuHB2bA",
    "outputId": "ff55cdd3-d39c-4715-8c43-a9bd8313179c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.45454545, 1.        , 0.57142857],\n",
       "       [0.34090909, 0.        , 0.        , 0.42857143],\n",
       "       [0.11363636, 0.        , 0.        , 0.        ],\n",
       "       [0.54545455, 0.54545455, 0.        , 0.        ]])"
      ]
     },
     "execution_count": 141,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    " import numpy as np\n",
    " def buildMatrix(sentences):\n",
    "    sen_len = len(sentences)\n",
    "    weighted_edge = np.zeros((sen_len, sen_len))\n",
    "    score = []\n",
    "    # 문장별로 그래프 edge를 Matrix 형태로 생성\n",
    "    for i in range(sen_len):\n",
    "      sum_i = 0\n",
    "      for j in range(sen_len):\n",
    "        if i != j:\n",
    "          sum_i += sentence_similarity(sentences[i], sentences[j])\n",
    "          weighted_edge[j][i] = sentence_similarity(sentences[i], sentences[j]) \n",
    "      score.append(sum_i)\n",
    "      weighted_edge[:,i] = weighted_edge[:,i] / sum_i\n",
    "\n",
    "    \n",
    "    return score, weighted_edge\n",
    "\n",
    "Text = \"딸기 바나나 사과 파인애플 수박. 바나나 사과 딸기 포도. 복숭아 수박. 파인애플 사과 딸기 바나나\"\n",
    "score, weighted_edge = buildMatrix(sent_tokenize(Text))    \n",
    "score\n",
    "weighted_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-YnryFGO8lg3",
    "outputId": "138a35c9-e775-4596-8e1c-38a5c056db20"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.4666666666666668, 1.1, 0.16666666666666666, 1.4]"
      ]
     },
     "execution_count": 142,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CfYbGdLp6wrE"
   },
   "source": [
    "### 3) 문장 중요도 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FlAJ0nVaB36Z"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def scoring(A, P, eps=0.0001, d=0.85, max_iter = 50):\n",
    "  weighted_edge = np.copy(P)\n",
    "\n",
    "  for iter in range(0, max_iter):\n",
    "    prev_score = np.copy(A)\n",
    "    summation = 0\n",
    "    for i in range(len(A)):\n",
    "      weighted_edge[:,i] = A[i]*p[:,i]\n",
    "      summation = sum(weighted_edge[i])\n",
    "      A[i] = (1-d) + d*summation\n",
    "\n",
    "    if np.sum(np.fabs(prev_score - A)) <= eps:\n",
    "      break\n",
    "  \n",
    "  return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZFqBZw_-4gfP",
    "outputId": "27739ca2-63b6-470e-c9e6-4370b1c96909"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.40742592990842, 1.02245543559791, 0.28591309303937273, 1.2763202909099132]"
      ]
     },
     "execution_count": 154,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring(score, weighted_edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EJBLc2jG60OR"
   },
   "source": [
    "### 4) 문서 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "SkIdmjkNBZfz",
    "outputId": "9f4eac2b-8f8c-4837-b7ce-ac8a6bfd653b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "E3EdMm8y_EOi",
    "outputId": "acddcdf1-e231-4a07-a5ab-e0dea283feda"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-156-d41a3c1686ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'e'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not list"
     ]
    }
   ],
   "source": [
    "b = ['a', 'b', 'c', 'd', 'e']\n",
    "a = [2,3]\n",
    "score[a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1DVvQdjSB5PE"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def summarize(text, n=10):\n",
    "  sentences = sent_tokenize(Text)\n",
    "  score, weighted_edge = buildMatrix(sentences) \n",
    "  sorted_index = (np.argsort(scoring(score, weighted_edge))[::-1])\n",
    "  result = []\n",
    "  for i in range(0, min(n, len(sentences))):\n",
    "    result.append(sentences[sorted_index[i]])\n",
    "  return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "EqjLqMOyR18k",
    "outputId": "4e43a254-43c5-42a9-b873-92ac5c51df6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "딸기 바나나 사과 파인애플 수박.\n",
      "파인애플 사과 딸기 바나나\n",
      "바나나 사과 딸기 포도.\n",
      "복숭아 수박.\n"
     ]
    }
   ],
   "source": [
    "summary = summarize(Text, 5)\n",
    "\n",
    "for sent in summary :\n",
    "  print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J16o9Y89WgNT"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i8Yj0ioJimhl"
   },
   "source": [
    "## 2.2 TextRank 직접 구현하기 (Graph 활용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I9kctoHX8RJm"
   },
   "outputs": [],
   "source": [
    "Text = \"딸기 바나나 사과 딸기 파인애플. 바나나 사과 딸기. 복숭아 파인애플. 파인애플 사과 딸기 바나나.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q-1Rfaqx7DFN"
   },
   "source": [
    "### 2) 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yWefbGlx8W3-"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wUAak7ej8IVp"
   },
   "outputs": [],
   "source": [
    "def sentences(text):\n",
    "    return sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iTtB08RJ8Ixa"
   },
   "source": [
    "### 3) 자카드 유사도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vU3qw-rBpiOc"
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "\n",
    "# 문장간 유사도 측정 (자카드 유사도 사용)\n",
    "def sentence_similarity(sentence1, sentence2):\n",
    "  pass\n",
    "\n",
    "sentence_similarity('나는 치킨을 좋아해','나는 치킨을 싫어해')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zuOJL2EW-uII"
   },
   "outputs": [],
   "source": [
    "def connect(nodes):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wbxnM_Cd7Fri"
   },
   "source": [
    "### 3) 그래프 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rKEErtAU-tmj"
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def rank(nodes,edges):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H9p3wVLLo7L4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ysIrWFvG7LX4"
   },
   "source": [
    "### 4) 문서 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6XQkxYkv-zxI"
   },
   "outputs": [],
   "source": [
    "def summarize(text,num_summaries=3):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UwlnlxyP8VM7"
   },
   "outputs": [],
   "source": [
    "summary=summarize(Text, 3)\n",
    "\n",
    "for sent in summary :\n",
    "  print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YPayQbC4iqmB"
   },
   "source": [
    "## 2.3 gensim을 활용한 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4-GdO7EigEg2"
   },
   "outputs": [],
   "source": [
    "\n",
    "print(docs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aLDc5qhTyXF3"
   },
   "outputs": [],
   "source": [
    "from gensim.summarization.summarizer import summarize\n",
    "summarize(docs[1]).split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g_1gyP1uX2z1"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "09 Prac. Document Summarization",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
